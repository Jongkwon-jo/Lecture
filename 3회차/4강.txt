이겸
안녕하십니까, 여러분. 이번 시간에는 '산업 지식형 에이전트 동작 원리'를 주제로 강의를 진행하겠습니다.
오늘 우리가 함께 살펴볼 내용은 래그, 즉 검색 증강 생성 기술과 SOP 기반 의사결정 구조, 그리고 o탐 방지 실무 가이드입니다. 

먼저 오늘의 전체적인 커리큘럼을 살펴보겠습니다! 총 5개의 섹션으로 구성되어 있는데요.
첫 번째 섹션에서는 산업 지식형 에이전트가 무엇인지 정의하고 교육의 전반적인 개요를 파악하는 시간을 가집니다. 두 번째 섹션은 래그 기반 문서 활용 자동화로, 문서 전처리부터 벡터 검색, 그리고 전체 파이프라인 구축까지 다루게 됩니다.
세 번째는 규정과 SOP, 매뉴얼을 기반으로 한 의사결정 구조를 설계하는 방법이고요. 네 번째 섹션에서는 실무에서 가장 중요한 o탐 방지를 위한 문서 관리 요령과 Hallucination 제어 방법을 배웁니다.
마지막으로 핵심 내용을 요약하면서 강의를 마무리하겠습니다.

오늘 교육의 학습 목표를 명확히 하고 시작하도록 하겠습니다.
학습 목표는 크게 세 가지로 정리할 수 있어요. 첫째, 산업 문서를 활용한 래그 파이프라인의 작동 원리를 이해하는 것입니다. 비정형 문서를 구조화하고 벡터 검색 시스템을 구축하는 원리를 습득하는 거죠.
둘째, 표준 운영 절차, 즉 SOP를 엘엘엠이 이해할 수 있는 트리 구조로 변환하는 의사결정 설계 능력을 기르는 겁니다.
마지막으로 Hallucination을 최소화하기 위한 메타데이터 관리와 검증 기법까지 다룹니다.
선행 지식으로는 Python 기초 프로그래밍, Rest API나 DB에 대한 기본적인 이해, 그리고 문서관리 시스템 경험이 있으면 좋습니다. 

자, 그럼 본격적으로 산업 지식형 에이전트가 무엇인지부터 정의하겠습니다.
간단히 말하면, 도메인 문서인 규정이나 매뉴얼, 그리고 사내 데이터를 활용해서 현장의 질의에 답하고 의사결정을 지원하는 지능형 에이전트 시스템입니다.
핵심 구성요소를 보면 네 가지로 나눌 수 있는데요. 먼저 LLM 코어가 있습니다. 언어를 이해하고 추론하는 엔진이죠.
두 번째는 Retrieval, 즉 래그를 통한 문서 및 데이터의 실시간 검색 기능입니다.
세 번째로 Domain Knowledge가 있어요. SOP나 규정, 매뉴얼 같은 지식베이스를 구축하는 거고요. 마지막으로 Policy와 Guardrail, 즉 보안 정책과 답변 제어 장치가 필요합니다.
기대 효과는 명확합니다. 정확도가 향상되고요, 근거 기반의 답변으로 신뢰성을 확보할 수 있습니다. 방대한 매뉴얼을 즉시 조회하니까 검색 시간이 단축되죠. 또한 표준 절차에 따른 작업을 유도해서 준수율도 높일 수 있습니다.
하지만 한계도 분명히 존재합니다. 최신성 유지를 위해서는 문서가 변경될 때마다 즉각적인 업데이트가 필요하고요. 원본 문서의 정확도가 성능을 좌우합니다. 사내 민감 정보에 대한 접근 권한 관리도 필수적이죠.

자, 이제 첫 번째 챕터로 들어가겠습니다. 래그 기반 문서 활용 자동화입니다.
도메인 문서를 어떻게 구조화하고, 검색하고, 생성에 연결하여 정확한 답변을 만들어내는지 그 방법을 함께 살펴보도록 하겠습니다.

먼저 래그의 개념과 왜 필요한지부터 이해하고 넘어가야 합니다. LLM은 강력하지만 분명한 한계가 있거든요.
첫 번째 한계는 할루시네이션, 즉 환각 현상입니다. 사실이 아닌 정보를 그럴듯하게 생성하는 현상인데요. 래그는 외부 지식 베이스에서 관련 정보를 검색해서 프롬프트에 추가하고, 이를 바탕으로 답변을 생성하기 때문에 이런 환각 현상을 억제할 수 있습니다.
두 번째 한계는 최신성 문제입니다. LLM은 학습 시점 이후의 최신 데이터를 모르거든요. 래그를 통해 실시간으로 변경되는 정보를 검색해서 생성 모델에 주입할 수 있죠.
세 번째는 도메인 특화 지식의 반영입니다. 공개된 인터넷 데이터가 아닌 사내 규정이나 SOP, 비공개 기술 문서 같은 폐쇄망 내부 지식을 활용할 수 있다는 게 핵심이에요.
산업 현장에서 기대할 수 있는 효과는 명확합니다. 작업 지침 준수율과 안전성이 향상되고요. 설비 장애가 발생했을 때 대응 시간을 단축할 수 있습니다. 감사 대응을 위한 명확한 근거도 제공할 수 있죠.

래그 시스템의 전체 구조를 한번 살펴보겠습니다. 크게 세 단계로 나눌 수 있어요. Indexing, Retrieval, 그리고 Generation입니다.
먼저 Indexing 단계를 보면요, 5개의 스텝이 있습니다. Ingest에서 다양한 포맷의 문서를 수집하고요. Parsing으로 텍스트를 추출하고 정제합니다. 전처리와 마스킹 작업이 이루어지죠.
Chunking에서는 의미 단위로 문서를 분할하고요. Embedding에서 텍스트를 벡터값으로 변환합니다. 마지막으로 Vector DB에 인덱싱해서 저장하는 거죠.
Retrieval 단계는 사용자 쿼리가 들어왔을 때 작동합니다. 유사도 기반으로 검색해서 Top-K를 추출하고요. Re-ranking으로 정확도를 재정렬합니다. Cross-Encoder를 사용하는 거죠.
Generation 단계에서는 LLM이 컨텍스트를 주입받아 답변을 생성하고요. Citation으로 출처와 근거를 표시합니다. 이게 바로 문서 수집부터 답변 생성까지의 End-to-End 파이프라인입니다.

문서 전처리는 래그 시스템의 품질을 결정하는 매우 중요한 단계입니다. 세 가지 주요 스텝으로 구성되어 있어요.
STEP 1은 포맷 변환, 즉 Extraction입니다. PDF나 Word 같은 다양한 소스 문서를 기계가 읽을 수 있는 텍스트로 변환하는 거죠. 이미지로 스캔된 문서는 OCR을 통해 텍스트화하고, Markdown으로 변환합니다.
STEP 2는 정규화, Normalization입니다. 불필요한 노이즈를 제거하고 용어를 표준화하는 단계인데요. 특수문자를 제어하고, 단위를 통일하고, 불용어를 제거하는 작업이 수행됩니다.
STEP 3은 품질 및 보안 처리입니다. 개인정보인 PII 같은 민감 정보를 마스킹하고요. 비식별화 작업과 정합성 검증을 진행합니다. 문서의 워터마크나 스탬프 같은 비텍스트 요소도 처리하죠.
버전 관리 전략도 중요합니다. 문서 고유 ID와 Revision 번호를 메타데이터에 포함시키고요. 규정의 시행일과 만료일을 태깅해서 구버전 검색을 방지합니다. 원본 파일로의 역추적 링크도 보존해야 해요.
주의사항으로는 표나 도면 데이터가 단순 텍스트 변환 시 구조가 깨지기 쉬우니 별도 처리가 필요하고요. 다단 편집 문서는 텍스트 추출 순서가 뒤섞이지 않도록 Layout Analysis를 선행해야 합니다.

벡터 데이터베이스 선택은 시스템 성능에 직접적인 영향을 미칩니다. 핵심 고려사항을 보면요, 데이터 규모가 천만 건 이상인지, 메타데이터 필터링 속도는 어떤지, 하이브리드 검색 지원 여부, 그리고 배포 환경이 SaaS인지 On-premise인지를 따져봐야 합니다.
주요 후보군을 비교해보면 전용 DB로는 Milvus, Qdrant, Weaviate가 있습니다. 성능과 기능이 우수하죠. 라이브러리로는 FAISS나 Chroma가 있는데 가볍고 빠른 구축이 가능해요.
기존 시스템을 확장하는 방식으로는 Elasticsearch kNN이나 PGVector가 있습니다. 운영이 용이하다는 장점이 있죠.
메타데이터 스키마 설계도 중요한데요. doc_id로 문서 고유 식별자를 부여하고요. revision으로 버전 관리를 하고, access_role로 열람 권한을 관리합니다. effective_dt로 유효 기간을 필터링하고, tags로 설비나 공정 태그를 리스트로 관리하죠.
현장 구축 팁을 드리자면, 보안이 엄격한 제조 현장은 외부 전송이 없는 On-premise 구축이 필수적입니다. 인덱싱 전략으로는 HNSW나 IVF, Flat 중에서 선택해야 하고요. 추천으로는 Milvus를 Docker로 구축하거나 PGVector를 사용하는 겁니다.

문서의 의미를 보존하는 청킹과 검색 정확도를 결정하는 임베딩 최적화는 래그 시스템의 핵심입니다.
임베딩 모델 선택부터 보면요. 한국어 특화 모델로는 ko-sbert, bge-m3, e5 계열 같이 한국어 문맥 이해도가 높은 모델을 선정해야 합니다. 도메인 파인튜닝도 고려할 수 있는데요, 제조나 산업 전문 용어 인식을 위해 사내 문서로 추가 학습하는 방법이죠.
청킹 전략을 보면 크기와 중복을 먼저 결정해야 해요. 보통 400에서 800 토큰 단위로 분할하고요. 문맥 단절을 방지하기 위해 10~20% 정도 중복을 설정합니다.
구조적 청킹도 있습니다. Markdown 헤더나 문단, 표 단위로 문서를 인식해서 분할하는 방식이죠.
성능 평가는 어떻게 할까요? nDCG나 Recall@k로 검색 결과 내에 정답이 포함되어 있는지 측정하고요. MRR, 즉 Mean Reciprocal Rank로 정답 문서의 순위를 평가합니다. 무엇보다 수동 샘플 리뷰가 중요한데요, 실제 질문 50개 정도에 대해 전문가 검증을 받는 게 가장 확실합니다.
특수 케이스 처리도 있어요. 표나 도면 데이터는 OCR로 텍스트 변환 후 캡션을 달아 검색 가능하도록 인덱싱하고요. 상위 문서 검색, 즉 Parent-Child 방식으로 작은 청크로 검색하되 LLM에는 전체 문맥을 제공해서 답변 품질을 향상시킬 수 있습니다.

정확한 답변을 위한 4단계 심화 검색 파이프라인을 살펴보겠습니다. Core Process와 Security Layer로 나뉩니다.
1단계는 쿼리 최적화, Query Refinement입니다. 사용자 질문의 의도를 파악하고 검색에 최적화된 형태로 변환하는 거죠. 오타를 교정하고, 동의어를 확장하고, 질문을 분해합니다.
2단계는 하이브리드 검색입니다. 키워드 매칭과 의미 기반 검색을 결합해서 재현율을 극대화하는 거예요. BM25로 키워드 검색을 하고 Vector로 의미 검색을 한 다음, Ensemble로 결합합니다.
3단계는 재랭킹, Re-ranking입니다. 검색된 문서들의 관련성을 정밀하게 재평가해서 순위를 조정하죠. Cross-Encoder를 사용해서 점수를 보정하고 Top-K를 추출합니다.
4단계는 가드레일, Guardrails입니다. 보안 정책과 접근 권한에 따라 부적절한 문서를 필터링하는 거예요. 접근 제어 ACL을 적용하고, 민감정보를 필터링하고, 유효성을 검증합니다.
이렇게 4단계를 거치면 정확하고 안전한 검색 결과를 얻을 수 있습니다.

이제 생성 단계를 살펴보겠습니다. 프롬프트 엔지니어링과 컨텍스트 관리가 핵심이에요.
프롬프트 설계부터 보면요, 역할을 명확히 해야 합니다. "산업 안전 전문가로서 답변하라" 같은 식이죠. 제약 조건도 중요한데요, "제공된 컨텍스트 내에서만 답변하고, 모르면 모른다고 답하라"처럼 명시해야 합니다.
인용도 필수입니다. "답변 끝에 반드시 근거 문서 ID와 페이지를 명시하라"고 지시하는 거죠.
컨텍스트 융합 전략을 보면, 중복 제거가 첫 번째입니다. 의미적으로 유사한 청크를 통합해서 토큰 낭비를 방지하고요. 최신성을 우선시해서 동일 내용 충돌 시 최신 버전을 우선 채택합니다. 메타데이터도 적극 활용해서 설비명이나 공정 코드 같은 정보를 답변에 반영하죠.
출력 형식도 다양하게 지원할 수 있어요. SOP 단계형으로 절차를 보여주거나, 체크리스트로 만들거나, 요약 테이블이나 JSON, XML 형식으로도 제공 가능합니다. 사용자의 질의 의도에 따라 최적의 포맷을 동적으로 선택하는 게 중요합니다.
정책 및 가드레일로는 PII 마스킹, Safety Filter, Compliance 검증이 있습니다. 작업자 이름이나 연락처 같은 개인정보를 비식별화하고요. 위험 조장이나 비속어를 차단하고, 사규 및 법적 규제 준수 여부를 사전 검증합니다.

래그 파이프라인의 전체 흐름을 정리해보겠습니다. 사용자 질문부터 피드백 수집까지의 End-to-End 순환 구조입니다.
Query Processing 단계에서는 사용자의 자연어 질문이 입력되고, 이를 벡터로 변환합니다. Retrieval & Context 단계에서는 하이브리드 검색으로 후보군을 추출하고, 재정렬해서 최적의 프롬프트를 조립하죠.
Generation 단계에서는 컨텍스트 기반으로 답변을 생성하고, 근거 문서를 인용해서 출처를 명시합니다.
Ops & Feedback 단계에서는 사용자 만족도를 수집하고요. 좋아요나 싫어요 피드백을 받아서 평가 및 로그 분석을 통해 지속적으로 개선합니다.
이 9단계가 순환하면서 시스템이 점점 더 똑똑해지는 거죠.

자, 이제 첫 번째 실습을 해보겠습니다. simple_래그.py 파일로 래그의 기본 구현을 살펴볼 거예요.
Sentence Transformers와 FAISS를 활용한 최소 기능 검색 에이전트를 구축하는 겁니다. 코드를 단계별로 살펴보면요.
첫 번째, 라이브러리와 데이터 준비입니다. numpy, sentence_transformers, faiss를 import하고요. 문서 데이터를 ID와 텍스트 쌍으로 준비합니다. SOP-001 안전모 착용 규정, MAN-101 압축기 점검 주기, REG-900 위험물 저장 규정 이렇게 세 개의 샘플 문서죠.
두 번째, 임베딩과 인덱싱입니다. paraphrase-multilingual-MiniLM-L12-v2 모델을 로드하고요. 모든 문서를 벡터화해서 FAISS 인덱스에 저장합니다. 코사인 유사도를 위해 L2 정규화를 적용하죠. IndexFlatIP는 내적 기반 인덱스입니다.
세 번째, 검색 함수입니다. 사용자 질의를 받아서 벡터로 변환하고, FAISS로 검색해서 가장 유사한 Top-k 문서를 반환합니다.
네 번째, 답변 생성입니다. 검색된 컨텍스트를 프롬프트에 주입해서 답변을 완성하는 거죠.
실행 결과를 보면 "안전모 규정은?"이라고 질문했을 때 SOP-001 문서에서 "안전모 착용은 작업장 입장 전 필수입니다"라는 정확한 답변을 찾아내는 걸 확인할 수 있습니다.
이게 바로 래그의 기본 원리입니다. 매우 간단하지만 핵심 개념이 모두 들어있죠.

래그 에이전트가 실제 산업 현장에서 어떻게 활용되는지 사례를 살펴보겠습니다.
제조 공정 관리 분야에서는 작업표준서, 즉 SOP를 즉시 검색할 수 있습니다. 복잡한 공정 매뉴얼에서 불량 원인을 5초 내에 파악해서 현장 조치 가이드를 제공하는 거죠. 실제로 생산 효율이 15% 증가한 사례가 있어요.
설비 유지보수 분야에서는 정비 이력과 치수를 확인합니다. 과거 고장 사례와 부품의 정확한 토크 값을 조회해서 정비 오류를 방지하는 거예요. 정비 대기시간이 40% 단축되었습니다.
산업 안전 관리에서는 위험성 평가 근거를 제시합니다. 작업 전 TBM 시에 해당 공정의 위험 요인과 안전 수칙을 근거 기반으로 안내하는 거죠. 안전 수칙 준수율이 98%까지 달성되었어요.
제약이나 식품 규제 분야에서는 감사 자동 대응이 가능합니다. GMP 규정 변경 사항을 실시간으로 반영하고, 감사관 질의 시 근거 조항을 자동으로 첨부하는 거죠. 문서 검색 시간이 90% 절감되었습니다.
이런 사례들을 보면 래그 시스템이 얼마나 실질적인 가치를 만들어내는지 알 수 있습니다.

이제 두 번째 챕터로 넘어가겠습니다. 규정과 SOP, 매뉴얼을 기반으로 한 의사결정 구조입니다.
규정과 표준 절차를 의사결정 트리로 연결해서 일관된 판단을 자동화하는 방법을 배워보겠습니다.

산업 문서는 일반 문서와 다른 특별한 특징들이 있습니다. 먼저 형식의 다양성이 있어요. SOP, 작업지도서, 매뉴얼, 도면, 법규 등 비정형 포맷이 혼재되어 있죠.
주요 문서 유형을 보면, SOP는 표준 운영 절차서이고요. WI는 작업 표준이나 지침서입니다. QM은 품질 매뉴얼, EHS는 환경, 안전, 보건 규정이죠.
변경 및 승인 관리도 중요합니다. 단순히 최신본이 아니라 승인된 유효 버전, 즉 Effective 버전을 식별해야 해요.
엄격한 접근 권한 관리가 필요한데요. 부서나 직급별로 열람 권한을 차등 적용해야 합니다. 레시피나 공정 조건 같은 민감한 정보는 더욱 그렇죠.
생명 주기 관리도 필수입니다. 작성, 검토, 승인, 배포, 개정, 폐기의 엄격한 주기를 관리해야 하고요.
핵심 관리 요소로는 용어와 코드의 표준화가 있습니다. 설비 코드, 공정 명칭, 위험 등급, 단위 같은 걸 표준화하지 않으면 검색이 실패하거든요. 예를 들어 "압축기", "Compressor", "CMP-01"이 같은 의미인데 통일되지 않으면 문제가 생기죠. 그래서 동의어 사전, 즉 Thesaurus가 필수적입니다.

비정형 텍스트 문서를 기계가 독해 가능한 데이터 스키마로 변환하는 방법을 살펴보겠습니다.
먼저 표준 필드 정의가 필요해요. 목적, 적용범위, 책임자, 절차 단계, 주의사항, 도구 등 필수 메타데이터를 필드 단위로 분리해서 정의하는 거죠.
문서 ID 체계도 중요합니다. DOC-FAMILY-NUM-REV 형식으로 고유 식별자를 부여하고 버전 관리 체계를 수립해야 해요. 예를 들면 SOP-PRD-001-R03 같은 식입니다.
계층 링크도 구축해야 하는데요. 상위 규정인 Policy와 하위 지침인 SOP, 그리고 양식인 Form 간의 참조 관계를 하이퍼링크나 벡터 관계로 연결하는 겁니다.
JSON 스키마 설계 예시를 보면요, doc_id로 "SOP-PRD-001-R03", title로 "압축기 안전 점검"을 명시하고요. steps 배열 안에 각 단계별로 seq 번호, action 내용, hazard 위험 요소, tool 필요 도구를 구조화합니다.
이렇게 구조화하면 어떤 효과가 있을까요? LLM이 문서의 논리적 흐름을 완벽하게 이해할 수 있고요. 특정 단계 단위의 정밀 검색이 가능해집니다. 변경 시에도 해당 섹션만 업데이트하면 되니까 관리가 용이하죠.

규정과 매뉴얼을 기반으로 한 자동화된 판단 로직 흐름을 8단계로 구성할 수 있습니다.
Input Phase부터 보면요, 첫 번째로 Data Input에서 센서나 로그, 질의 데이터를 수집합니다.
Logic Phase로 넘어가면, Rule Matching에서 IF-THEN 규칙을 적용해서 SOP나 매뉴얼을 매핑하고요. Severity Check에서 치명도 레벨을 평가합니다. Critical인지 Major인지 판단하는 거죠.
Output Phase에서는 Action Plan으로 초안 조치를 생성하고 Escalation 경로를 결정합니다. 여기서 Decision Engine이 활성화되는데요.
Validation 단계에서 안전이나 규정 위배 여부를 검증하고, Simulation을 돌려봅니다. Decision 단계에서 최종 승인이나 반려를 결정하는데, Human-in-the-loop 방식으로 사람이 개입할 수 있어요.
Final Output에서는 지침을 전달하고 제어 명령을 수행합니다. 마지막으로 Feedback 단계에서 결과를 로깅하고 모델 재학습에 반영하는 거죠.
이런 8단계 흐름을 통해 일관되고 추적 가능한 의사결정을 자동화할 수 있습니다.

도메인 지식을 효과적으로 통합하기 위한 핵심 전략을 세 가지로 정리할 수 있습니다.
첫째, 규정 대 사례의 균형입니다. 규정은 절대적 판단 기준으로 사용하고요. 과거 사례는 보조 근거로 활용해서 판단의 일관성과 유연성을 동시에 확보하는 거예요.
둘째, 지식 그래프 구축입니다. 설비, 부품, 증상, 조치 간의 관계를 그래프로 모델링하면요. 키워드 매칭의 한계를 넘어서 문맥적 추론이 강화됩니다.
셋째, Tool 호출, 즉 에이전트ic Actions입니다. 단순 답변 생성을 넘어서 계산기를 쓰거나, ERP를 조회하거나, 티켓을 발행하는 등 외부 도구를 직접 호출해서 실질적 업무를 수행할 수 있어요.
통합 아키텍처를 보면 LLM이 중앙에 있고요. 래그와 Tools가 연결되어서 Actionable Insight를 만들어내는 구조입니다.
책임 추적성도 중요한데요. 출처 문서와 구체적 조항을 명시하고요. 참조된 문서의 버전을 기록하고, 해당 규정의 최종 승인자 정보까지 표기해야 합니다. 이게 있어야 나중에 감사 대응이 가능하죠.

정확한 답변 생성을 위한 문서 우선순위와 조합 정책을 살펴보겠습니다. 최신성과 신뢰성 중 무엇을 우선할지 전략적 선택이 필요해요.
최신성 우선 전략은 "가장 최근 작성된 문서를 현재의 진실로 간주한다"는 철학입니다. Time Decay Score를 적용해서 문서 생성일이 오래될수록 검색 점수를 낮추는 거죠. Score는 Similarity 곱하기 0.95의 몇 개월 지났는지 제곱으로 계산합니다.
장점은 현장 트러블슈팅이나 긴급 변경사항에 빠르게 대응할 수 있다는 거고요. 잠재 위험은 검증되지 않은 임시 정보가 포함될 수 있다는 겁니다.
신뢰성 우선 전략은 "승인 및 검증 절차를 거친 문서만 진실로 간주한다"는 철학이에요. Status가 Approved인 것만 필터링하고, 버전 체크를 해서 임시본을 제외합니다.
장점은 규제 준수나 감사 대응 시 법적 리스크를 최소화한다는 거죠. 잠재 위험은 개정되었으나 아직 승인 전인 최신 중요 정보가 누락될 수 있다는 겁니다.
구현 전략으로는 시간 가중, 권한 가중, 소스 다양성이 있어요. 관리자나 품질보증 팀 같은 신뢰할 수 있는 작성자의 문서에 가산점을 주고요. MMR 같은 기법으로 특정 문서군에 편중되지 않도록 다양한 출처를 확보하는 겁니다.
권장 설정을 보면 최대 컨텍스트 토큰은 4,096, 청크 개수는 Top-5, 최소 유사도 스코어는 0.85 정도가 적절합니다.

두 번째 실습으로 SOP 기반 QA 시스템을 구축해보겠습니다. 조건과 조치 구조를 활용한 절차적 답변 자동화 로직이에요.
첫 번째, 데이터 구조화입니다. SOP를 딕셔너리 리스트로 정의하는데요. 각 항목이 id, step, cond 조건, act 조치 필드를 가집니다. 예를 들면 SOP-001의 step 1에서 "작업장 입장 전"이라는 조건에 "안전모 확인"이라는 조치가 매핑되는 식이죠.
두 번째, 조건 벡터화입니다. '조건' 필드만 추출해서 임베딩하고 정규화를 수행합니다. paraphrase-multilingual-MiniLM-L12-v2 모델을 사용하고요. L2 norm으로 정규화합니다.
세 번째, 질의 매칭과 필터링입니다. 사용자 질의가 들어오면 역시 벡터로 변환하고요. 코사인 유사도를 계산합니다. Dot Product를 사용하는 거죠. 임계값을 설정해서, 예를 들어 0.45 미만이면 "조건을 구체화해주세요"라고 안내합니다.
네 번째, 권고 생성입니다. 가장 적합한 조건의 '조치'를 반환하고, 근거로 ID와 Step을 명시하며, 유사도 점수도 함께 제공합니다.
실행 결과를 보면요, "작업장 들어가기 전에 무엇 확인?"이라고 질문했을 때 "권고: 안전모 확인, 근거: SOP-001, 유사도 0.82"라는 답변이 나옵니다.
이렇게 조건과 조치를 구조화하면 LLM 없이도 규칙 기반으로 정확한 답변을 제공할 수 있어요. 비용도 절감되고 응답 속도도 빠르죠.

SOP 기반 의사결정 시스템이 현장에서 어떻게 활용되는지 세 가지 시나리오를 보겠습니다.
현장 모바일 QA에서는 사진이나 음성으로 질의할 수 있어요. 현장에서 설비 사진을 찍거나 음성으로 질문하면요. SOP를 분석해서 관련 근거와 함께 즉시 답변을 제공합니다. 실시간으로 문제를 해결하는 거죠.
비상 상황 대응에서는 e-SOP 상황판과 연동됩니다. 화재나 누출이 감지되면요. 상황실 화면에 e-SOP 기반의 단계별 대응 지침을 자동으로 띄워줍니다. 골든타임을 확보하는 게 핵심이에요.
신규 인력 교육에서는 표준절차 AI 튜터링이 가능합니다. 신입 사원이 복잡한 작업 절차를 대화형으로 학습할 수 있도록요. AI가 1대1 튜터가 되어서 표준 절차를 가이드합니다. 숙련도를 조기에 확보할 수 있죠.

래그 기반 산업 지식형 에이전트 도입에 따른 정량적 성과 지표를 살펴보겠습니다. 2025년 4분기 데이터예요.
KPI 성과 지표를 비교해보면요. 평균 검색 시간이 도입 전 12분에서 도입 후 1.5분으로 줄어들었습니다. 무려 87.5% 단축된 거죠.
1차 응답 정확도는 72%에서 96.5%로 향상되었어요. 24.5%포인트나 올라간 겁니다.
규정 미준수율은 8%에서 0.5%로 감소했습니다. 93.7%나 개선된 거예요.
감사 지적 건수도 분기당 14건에서 2건으로 줄어들었습니다. 85.7% 감소했죠.
종합적으로 보면 업무 효율은 8배 증가했고요. 치명적 인적 오류는 제로를 달성했습니다. 변경 이력 추적은 100% 완벽하게 이루어지고 있어요.
그림 1을 보시면 정보 검색 소요 시간 단축 효과가 시각적으로 드러나고요. 그림 2에서는 응답 정확도와 신뢰도 향상을 확인할 수 있습니다.
이런 수치들이 보여주는 건 명확합니다. 래그 시스템은 단순한 기술적 혁신이 아니라 실질적인 비즈니스 가치를 창출한다는 거죠.

세 번째 챕터로 넘어가겠습니다. 오탐 방지를 위한 문서 관리 요령입니다.
할루시네이션, 즉 오탐의 원인을 문서, 검색, 생성 단계별로 차단하는 방법을 배워보겠습니다.

Hallucination, 즉 할루시네이션이 무엇인지부터 정확히 이해해야 합니다. AI 모델이 사실이 아닌 정보를 마치 사실인 것처럼 확신을 가지고 생성하는 현상이에요. 산업 현장에서는 잘못된 작업 지시나 규정 위반을 유발할 수 있어서 치명적입니다.
발생 트리거를 보면요. 첫째는 Context 부족입니다. 검색 실패로 인한 정보 공백 때문에 래그가 관련 문서를 못 찾으면 LLM이 지어내기 시작하는 거죠.
둘째는 모호한 프롬프트예요. 지시 사항이 불명확할 때, 예를 들어 "적당히 요약해"처럼 제약 조건이 없으면 발생합니다.
셋째는 도메인 외삽입니다. 학습 지식을 무리하게 적용하는 건데요. 일반 상식을 특수 산업 현장에 그대로 적용하려 할 때 문제가 생기죠.
주요 발생 유형을 보면, 지식 부재형은 학습 데이터나 검색된 문서에 없는 내용을 허구로 창조하는 겁니다. 예를 들어 존재하지 않는 안전 규정 번호를 인용하는 거죠.
과잉 일반화는 일부 패턴을 무리하게 확장 적용해서 예외 상황을 무시하는 거예요. "모든 밸브는 시계 방향으로 잠근다"고 했는데 반대 나사 밸브를 무시하는 식입니다.
수치 및 관계 왜곡도 있습니다. 문서 내 숫자를 임의로 변경하거나 인과관계를 반대로 해석하는 거죠. "온도가 50도 이상이면"을 "이하이면"으로 잘못 해석하는 경우가 있어요.

오탐 발생의 근본 원인을 분석하고 문서 품질 관리 방법을 알아보겠습니다.
근본 원인은 크게 두 가지로 나뉩니다. 첫째는 문서 품질 문제예요. 원본 문서 자체에 오류나 모순이 있거나, OCR 품질이 낮거나, 중복되고 구버전이 혼재되어 있는 경우죠.
둘째는 기술적 파이프라인 이슈입니다. 청킹이 부적절해서 문맥이 단절되거나, 임베딩 모델이 도메인 용어를 오해하거나, 검색 스코어 임계값이 잘못 설정된 경우예요.
문서 품질 관리 체크리스트를 보면요. OCR 품질 검증이 첫 번째입니다. 스캔 문서의 텍스트 추출 정확도를 반드시 검증해야 해요. 특히 숫자나 특수 기호가 잘못 인식되는 경우가 많거든요.
중복 제거도 중요합니다. 동일 내용의 다른 버전 문서를 필터링해야 하고요. 민감정보 마스킹으로 개인정보나 보안 정보를 비식별화해야 합니다.
메타데이터 완전성도 체크해야 해요. 문서 ID, 버전, 승인일 등이 누락되지 않았는지 확인하고요. 용어 표준화를 위한 동의어 사전을 구축해야 합니다.
정합성 검증도 필수인데요. 문서 간 모순이나 충돌을 사전에 감지해야 합니다. 유효 기간 관리로 만료된 문서는 자동으로 비활성화하는 정책도 필요하죠.

메타데이터 관리와 수명주기 정책, 그리고 검증 및 모니터링 시스템에 대해 알아보겠습니다.
메타데이터 관리에서는 유효 기간 설정이 핵심이에요. 문서의 시행일과 만료일을 명시해서 만료된 문서는 검색에서 자동으로 제외되도록 해야 합니다.
접근 권한 연동도 중요한데요. 사용자의 역할이나 부서에 따라 열람 가능한 문서를 필터링하는 겁니다. 레시피나 공정 조건 같은 민감한 정보는 더욱 엄격하게 관리해야 하죠.
수명주기 정책을 보면, 작성부터 검토, 승인, 배포, 개정, 폐기까지 각 단계별로 명확한 규칙이 있어야 해요. 승인되지 않은 초안은 절대 검색 대상에 포함되면 안 됩니다.
검증 및 모니터링 시스템은 두 가지 방식으로 운영됩니다. Real-time Fact Check로 답변 생성 직후 컨텍스트와의 일치도를 자동 검증하고요. Contradiction Detection으로 답변 내 모순을 탐지합니다.
Offline 피드백 수집도 중요해요. 사용자로부터 좋아요나 싫어요 피드백을 받고, 전문가가 주기적으로 샘플 리뷰를 해서 오답을 수집하고 원인을 분석합니다. 이걸 통해 지속적으로 시스템을 개선하는 거죠.

세 번째 실습으로 오탐 감지 시스템을 구축해보겠습니다. hallucination_check.py 파일이에요.
벡터 유사도 기반으로 할루시네이션을 감지하는 원리입니다. 코드를 단계별로 보면요.
첫 번째, 라이브러리와 문서 준비입니다. numpy와 sentence_transformers를 import하고요. 신뢰할 수 있는 참조 문서를 준비합니다. 예를 들어 "안전모는 입장 전 필수", "압축기는 500시간 주기" 같은 식이죠.
두 번째, 참조 문서 벡터화입니다. 모든 참조 문서를 임베딩해서 벡터 배열로 만들고 정규화합니다.
세 번째, 유사도 검증 함수입니다. LLM이 생성한 답변을 벡터로 변환하고요. 참조 문서들과의 코사인 유사도를 계산합니다. 최대 유사도가 임계값 이상이면 신뢰할 수 있는 답변으로 판단하고, 미만이면 할루시네이션 의심으로 플래그를 올립니다.
네 번째, 실행 및 결과입니다. "안전모는 현장 입장 전에 꼭 착용해야 합니다"라는 답변은 유사도 0.89로 OK가 나오고요. "안전모는 선택 사항입니다"라는 답변은 유사도 0.31로 Warning이 뜹니다.
이렇게 벡터 유사도를 활용하면 LLM 답변의 신뢰성을 자동으로 검증할 수 있어요. 임계값은 보통 0.7에서 0.8 사이로 설정하는데, 도메인 특성에 맞게 조정해야 합니다.
실무에서는 이 검증을 답변 생성 직후 자동으로 실행하고요. Warning이 뜨면 사용자에게 "이 답변은 검증이 필요합니다"라고 안내하거나, 아예 답변을 보류하고 전문가 검토를 요청할 수도 있습니다.

래그 시스템은 한 번 구축하고 끝나는 게 아닙니다. 지속적인 개선이 필요하죠.
데이터 큐레이션부터 보면요. 오답 사례를 수집해서 근본 원인을 분석하고요. 문서를 보강하거나 청킹 전략을 조정합니다. 동의어 사전도 지속적으로 업데이트해야 해요.
파라미터 튜닝도 중요합니다. 청크 크기나 중복 비율, Top-K 개수, 유사도 임계값 같은 걸 주기적으로 재평가하고 최적화하는 거죠. A/B 테스트로 변경 효과를 측정하는 것도 좋습니다.
모델 업그레이드는 어떻게 할까요? 더 나은 임베딩 모델이 나오면 마이그레이션을 검토하고요. LLM도 새 버전으로 업데이트하되, 반드시 회귀 테스트를 진행해야 합니다. 기존에 잘 작동하던 기능이 깨지지 않는지 확인하는 거죠.
거버넌스 운영도 필수예요. 문서 승인 프로세스를 정립하고요. 정기 감사를 실시해서 시스템 성능과 컴플라이언스를 점검합니다. 사용자 교육도 지속적으로 진행해서 시스템을 올바르게 활용하도록 유도하는 게 중요합니다.
개선 사이클을 보면, 모니터링 → 피드백 수집 → 분석 → 개선 조치 → 검증 → 배포 → 다시 모니터링, 이런 식으로 순환합니다. 보통 월 단위나 분기 단위로 개선 사이클을 돌리는 게 적절해요.

오늘 배운 내용을 세 가지 핵심 원칙으로 요약하겠습니다.
첫 번째, Process, 즉 프로세스입니다. 래그 파이프라인을 제대로 구축하는 게 핵심이에요. Indexing에서 문서를 수집하고 전처리하고 벡터화해서 저장하고요. Retrieval에서 하이브리드 검색과 재랭킹으로 정확한 문서를 찾아내고. Generation에서 프롬프트 엔지니어링과 가드레일로 안전한 답변을 생성하는 겁니다.
두 번째, Structure, 즉 구조화입니다. 비정형 문서를 기계 독해 가능한 형태로 변환하는 거죠. JSON 스키마로 SOP를 구조화하고요. 의사결정 트리를 설계해서 일관된 판단을 자동화하고. 지식 그래프로 도메인 지식을 연결하는 겁니다.
세 번째, Reliability, 즉 신뢰성입니다. 할루시네이션을 제어하는 게 가장 중요해요. 문서 품질 관리로 원본의 정확성을 확보하고요. 메타데이터 관리로 버전과 권한을 통제하고. 검증 시스템으로 답변의 신뢰도를 실시간 체크하는 겁니다.
이 세 가지 원칙, Process, Structure, Reliability를 기억하시면요. 어떤 산업 현장에서든 성공적으로 지식형 에이전트를 구축하실 수 있을 겁니다.
실무에 적용하실 때는 작게 시작하세요. 파일럿 프로젝트로 한 개 부서나 한 개 공정부터 시작해서요. 성과를 검증하고 점진적으로 확대하는 게 안전합니다. 사용자 피드백을 적극적으로 수집하고 지속적으로 개선하는 것도 잊지 마세요.

마지막으로 질의응답 시간을 갖겠습니다. 오늘 50분 동안 산업 지식형 에이전트의 동작 원리를 함께 살펴봤는데요.
질문이 있으신 분은 자유롭게 해주시기 바랍니다. 특히 실습 코드와 관련해서 궁금한 점이나, 실제 현장 적용 시 예상되는 어려움, 또는 특정 산업에 맞는 커스터마이징 방법 등 어떤 질문이든 환영합니다.
권장 논의 주제를 몇 가지 제시하면요. 첫째, 기존 문서 관리 시스템과의 통합 방안은 어떻게 될까요? 둘째, 폐쇄망 환경에서 구축할 때 주의사항은 무엇일까요? 셋째, ROI 측정과 경영진 설득은 어떻게 하면 좋을까요?
넷째, 다국어 지원이 필요한 경우 어떻게 대응해야 할까요? 다섯째, 법적 책임 문제는 어떻게 해결할 수 있을까요? 여섯째, 유지보수 인력과 비용은 어느 정도 필요할까요?
이런 주제들에 대해 함께 논의하면서 각자의 현장에 맞는 솔루션을 찾아가시면 좋겠습니다. 오늘 교육이 여러분의 업무에 실질적인 도움이 되기를 바라며, 질문 받겠습니다. 감사합니다.

