안녕하세요, 여러분. 국립창원대학교 PRU 재직자 교육 프로그램에 오신 것을 환영합니다. 오늘 우리가 함께 탐구할 주제는 '프롬프트 엔지니어링 핵심 전략'이에요.
화면을 보시면 역할 정의, 조건 설정, 그리고 공식화라는 세 가지 키워드가 보이시죠? 이 세 가지가 바로 오늘 여러분이 가져가실 핵심 도구입니다. 목표는 명확합니다. 재현 가능한 고품질 AI 출력을 확보하는 것이죠.

오늘 강의는 총 9개의 섹션으로 구성되어 있어요. 크게 보면 이론과 실습, 그리고 실무 적용이라는 세 개의 블록으로 나뉩니다.
첫 번째 블록에서는 프롬프트 엔지니어링의 개념부터 역할 정의, 조건 설정, 공식화 방법론까지 이론적 토대를 다질 거예요. 두 번째 블록에서는 Python과 OpenAI API를 활용한 5가지 실전 예제를 직접 코딩하면서 체득하게 되죠. 마지막으로 행정, 교육, 데이터 분석 분야의 실제 사례를 살펴보고, 여러분만의 솔루션을 제작하는 워크숍으로 마무리합니다.

본 과정을 통해 여러분이 달성하게 될 다섯 가지 핵심 역량을 정리해볼까요? 첫째, 페르소나 설계를 통한 역할 정의 능력입니다. 모델에게 명확한 정체성을 부여하는 기술이죠.
둘째, 조건과 제약, 출력 형식을 체계적으로 기술하는 능력이에요. 셋째, 프롬프트 공식을 실무에 적용하는 실행력입니다. 넷째, Python을 활용한 템플릿화와 자동화 기술이죠. 마지막으로 품질 평가와 A/B 테스트를 통한 지속적 개선 능력까지, 이 다섯 가지가 여러분의 무기가 될 겁니다.

자, 그렇다면 프롬프트 엔지니어링이 정확히 무엇일까요? 한마디로 정의하자면, AI 모델의 행동을 설계하고 최적화하는 핵심 기술입니다.
단순히 질문을 던지는 게 아니라, 모델의 역할과 어조, 심지어 추론 방식까지 구체적으로 정의하여 원하는 결과를 유도하는 거예요. 최근 멀티모달 기능과 Function Calling이 확산되면서, 복잡한 업무 프로세스를 자동화하는 핵심 역량으로 떠올랐죠. 문서 작성부터 코드 생성, 데이터 분석, 고객 지원까지 전 산업 분야에서 고품질 AI 출력을 얻기 위한 필수 기술로 자리잡고 있습니다.

첫 번째 핵심 개념, 역할 정의로 들어가볼까요? 모델에게 명확한 페르소나를 부여하는 것이 왜 중요할까요? 세 가지 측면에서 살펴보겠습니다. 
첫째, 전문가 페르소나를 부여하면 답변의 스타일과 형식이 일관되게 유지돼요. "당신은 10년 차 행정 전문가입니다"라고 지정하면, 모델은 해당 도메인의 용어와 규칙을 준수하게 되죠. 둘째, 탐색 비용이 극적으로 감소합니다. 모호한 답변이나 불필요한 서론이 줄어들어, 원하는 결과에 더 빠르게 도달할 수 있어요. 셋째, 도메인 적합도와 신뢰성이 향상됩니다. 실무에 바로 적용 가능한 수준의 출력을 얻을 수 있죠.

정교한 페르소나 설정을 위한 5가지 핵심 요소를 알아봅시다. 이건 단순한 체크리스트가 아니라, 모델의 행동 범위를 제어하는 설계 프레임워크예요.
첫째, System Persona 입니다. 직무, 숙련도, 구체적인 책무를 명시하여 전문가로서의 정체성을 확립합니다.
둘째, Voice & Tone 입니다. 상황에 맞는 어조와 언어 수준을 설정하죠. 
셋째, 도메인 규칙입니다. 특정 분야의 용어집과 스타일 가이드를 사전에 주입해요. 
넷째, 도구 사용입니다. 함수 호출이나 웹 검색 같은 외부 도구 사용의 시점과 원칙을 정의합니다. 
다섯째, 경계 조건입니다. 모델이 수행하지 말아야 할 행동, 이른바 'Negative Constraints'를 명확히 제한하는 거죠. 
이 다섯 가지가 모두 갖춰져야 진정한 전문가 페르소나가 완성됩니다.

역할을 정의했다면, 이제 출력을 정교하게 제어할 차례입니다. 조건 설정은 네 가지 유형으로 분류할 수 있어요.
첫째, 출력 형식 지정입니다. "결과는 반드시 json 포맷으로만 출력하고, 'summary'와 'bullets' 키를 포함하시오"처럼 구조를 강제하는 거죠. 
둘째는 품질 기준이에요. "각 주장에 대해 사실적 근거를 2개 이상 제시하고, 출처 링크를 명시하시오"와 같은 요구사항이에요. 
셋째, 리소스 제약입니다. "인사말이나 서론은 생략하고, 300 토큰 이내로 핵심 내용만 기술하시오"처럼 효율성을 추구합니다. 
넷째, 정책 및 안전은 "개인정보는 마스킹 처리하여 출력하시오"와 같은 윤리 가이드라인이죠. 이 네 가지를 조합하면 거의 모든 비즈니스 요구사항을 충족할 수 있습니다.

여기서 중요한 질문 하나 던져볼게요. 왜 우리는 프롬프트를 '공식화'해야 할까요?
네 가지 핵심 이점이 있습니다. 먼저 재현성 때문입니다. 
누구나 같은 입력을 주었을 때 일관된 결과를 얻을 수 있어요. 품질의 변동성이 최소화되는 거죠. 
다음으로는 협업성인데요. 명확한 공식은 팀원 간의 프롬프트 공유와 버전 관리를 용이하게 합니다. 
자동화는 표준화된 프롬프트는 테스트 파이프라인과 통합하기 쉬워서, CI/CD를 실현할 수 있어요. 
마지막 확장성입니다. 도메인별로 최적화된 프롬프트를 템플릿 라이브러리로 구축하여, 다양한 업무에 신속하게 재사용할 수 있죠. 
경험에 의존하는 '감'이 아닌, 공학적 설계를 통해 예측 가능한 AI 시스템을 구축하는 겁니다.

자, 이제 실전 공식을 공개합니다. 체계적인 프롬프트 엔지니어링을 위한 7단계 구성요소 흐름이에요.
역할, Role은 전문가 페르소나를 정의합니다.
목표, Objective는 수행해야 할 과제를 명시하죠.
맥락, Context는 배경 정보와 상황을 제공해요.
입력, Input은 처리할 데이터나 문서를 지정합니다.
형식, Format은 출력 형태를 지정하죠.
제약, Rules는 금지 사항과 한계를 설정해요. 
마지막 평가, Eval은 결과 검증 기준을 마련합니다. 
중요한 건, 이 흐름이 순차적이지만 반복적이라는 점이에요. 특히 평가 단계에서 만족스럽지 않다면, 역할이나 제약을 수정하여 최적화하는 거죠.

프롬프트 출력 결과의 품질을 어떻게 측정할까요? 5대 핵심 지표를 소개합니다.
첫째, 정확성은 모델의 응답이 사실과 논리에 부합하며, 환각이 없는지 Low, Medium, High로 평가해요. 
둘째, 완전성입니다. 사용자가 요청한 모든 세부 사항을 빠짐없이 다루었는지 확인하죠. 
셋째, 형식 준수는 json 구조나 특정 태그 사용 등 지정된 포맷을 엄격히 지켰는지 Pass 또는 Fail로 판단합니다. 
넷째, 근거성은 주장에 대한 신뢰할 수 있는 출처가 0건인지, 1건인지, 두 건 이상인지 확인해요. 
다섯째, 안전성은 개인정보나 편향적 표현, 유해 콘텐츠가 필터링되었는지 검증하죠. 
이 루브릭은 자동화된 테스트 스크립트에서 assert 문으로 변환하여 정량적 평가 시스템을 구축하는 데 사용됩니다.

실제 예시로 차이를 체감해봅시다. 나쁜 프롬프트는 이렇게 생겼어요. "이 문서 요약해줘."
역할도 없고, 대상 독자도 불분명하고, 글자 수 제한도 없죠. 모델이 임의로 판단하게 되는 겁니다. 결과는? 너무 길거나 짧은 요약, 핵심 누락, 그리고 줄글 형태의 비정형 텍스트예요. 
반면 좋은 프롬프트는 이렇습니다. "당신은 행정 문서 전문가입니다. 아래 공문을 다섯 문장 공식 언어로 요약하세요. 핵심 3개 불릿과 근거 문장을 인용하고, json 포맷으로만 출력하세요." 
보시다시피 역할, 목표, 포맷, 제약이 완벽히 명시되어 있죠. 결과는 구조화된 json 데이터로, 시스템 자동화와 후처리가 가능합니다.

모델의 논리적 사고와 문제 해결 능력을 극대화하는 다섯 가지 고급 전략을 소개합니다.
첫째, Chain-of-Thought 입니다. "단계별로 생각해보자"와 같이 중간 사고 과정을 명시하여 복잡한 추론의 정확도를 높이는 거죠. 
둘째는 ReAct, Reason + Act 입니다. 생각과 행동을 교차하며 검색이나 외부 도구를 호출하여 사실에 기반한 답을 도출해요. 
셋째, Self-Consistency 또는 ToT는 여러 번의 추론 경로를 탐색하여 가장 일관된 답을 선택하거나, 생각의 나무를 확장합니다. 
넷째, Few-shot Prompting은 양질의 입출력 예시를 제공하여 모델이 문맥과 패턴을 즉각적으로 학습하도록 유도하죠. 
마지막 Self-critique 입니다. 모델이 생성한 답변을 스스로 비판하고 수정하는 루프를 통해 완성도를 개선하는 겁니다. 단순한 지시를 넘어, 복잡한 문제를 단계별로 해결하도록 모델의 사고 과정을 설계하고 제어하는 기법들이에요.

이론은 여기까지입니다. 이제 실습으로 들어가기 전에 개발 환경을 점검해볼까요?
다섯 가지가 필요해요. 
첫째, Python 3.10 이상과 Jupyter Notebook 또는 VS Code가 설치되어 있어야 합니다. 
둘째, 필수 라이브러리 설치입니다. 터미널에서 p-i-p install openai, ollama, jinja-two를 실행하세요. 
셋째, OpenAI의 API Key를 발급받아 환경변수로 설정해야 해요. 
넷째, 선택 사항이지만 로컬 모델을 활용하려면 Ollama를 설치하고 ollama pull llama-three를 실행하죠. 
다섯째, 실습용 예제 텍스트나 CSV 데이터 파일을 준비하시면 됩니다. 준비되셨나요? 그럼 시작합니다.

첫 번째 실습, OpenAI의 API를 활용한 가장 기초적인 코드 패턴입니다.
세 단계로 구성돼요. 1단계는 클라이언트 초기화로, OpenAI 라이브러리를 임포트하고 API Key를 로드하여 클라이언트 인스턴스를 생성합니다. 
2단계는 메시지 리스트 구성입니다. 대화의 맥락을 형성하는 리스트죠. system은 Role을, user는 실제 질문을 담당해요. 
3단계 API 호출 및 응답에서는 모델을 지정하고 메시지를 전송합니다. temperature로 창의성을 조절하는 거죠. 핵심 포인트를 하나 말씀드리면, System Role이 모델의 정체성과 행동 지침을 설정하는 가장 강력한 수단이라는 겁니다. "당신은 ~ 전문가입니다"라고 정의하는 것이 프롬프트 엔지니어링의 시작이에요.

두 번째 실습은 구체적인 페르소나와 어조, 대상을 명시하여 응답 품질을 향상시키는 겁니다.
세 단계로 나누어서 보겠습니다. 1단계는 상세 페르소나 설계입니다. 
모델의 직업을 공문서 전문가로,
어조는 공식적인 어조,
독자는 교육생으로 명확히 정의하여 system_role 변수에 저장하죠. 
2단계는 시스템 메시지를 주입하는 건데요. 설계한 페르소나를 role, system의 content로 전달합니다. 이게 대화의 전반적인 규칙이 되는 거예요. 
마지막 3단계에서는 구체적인 태스크를 요청합니다. 사용자 메시지에서는 요약, 작성과 같은 구체적인 작업, 제약 조건을 제시합니다. 
왜 상세한 역할이 중요할까요? 단순히 "요약해줘"라고 할 때와 달리, 전문가 페르소나를 부여하면 불필요한 서론을 줄이고 전문 용어를 적절히 사용한 고품질 결과물을 얻을 수 있어요.

세 번째 실습은 response-format 파라미터를 사용하여 완벽한 JSON 구조로 제어하는 방법입니다.
먼저 명확한 스키마를 지시합니다. 예를 들어, 프롬프트 내에 "json으로 출력하라"는 지시와 함께 원하는 Key, Value 구조를 명시해야 해요. 
두번째는 json 모드 활성화를 위해 API 호출 시, response-format에 "type", "json_object"를 추가하여 강제로 유효한 json을 생성하게 하는 거죠. 
마지막으로 파싱 및 데이터 활용입니다. 응답이 문자열 형식이므로 json.loads를 통해 Python 딕셔너리로 변환하여 사용합니다. 
주의사항이 하나 있어요. response-format을 사용할 때는 반드시 프롬프트 텍스트 내에도 "json"이라는 단어를 포함해야 합니다. 그렇지 않으면, 오류가 반환될 수 있어요.

네 번째 실습은 LLM이 외부 함수를 실행해야 할 시점을 판단하고 적절한 인자를 생성하도록 유도하는 기법입니다.
세 단계로 살펴보겠습니다. 
1단계, 도구 정의입니다. 모델이 사용할 수 있는 함수를 json 스키마 형태로 정의해요. 함수의 이름, 설명, 파라미터 구조를 명시하는 거죠. 
2단계는 API 호출 시 tools 파라미터에 정의한 도구 리스트를 전달하여 모델이 이를 인지하게 합니다. 
3단계는 모델의 판단 확인으로, 모델은 직접 함수를 실행하지 않고, "어떤 함수를 어떤 인자로 실행해야 하는지" json으로 응답해요. 
핵심은 모델은 '실행'하지 않고 '결정'만 한다는 겁니다. 개발자는 모델이 준 json을 파싱하여 실제 코드를 실행하고, 그 결과를 다시 모델에게 프롬프트로 알려줘야 하는 거죠.

다섯 번째 실습은 모델에게 양질의 예시를 미리 보여주어 원하는 형식과 품질을 유도하는 few-shot 기법이에요.
세 단계 접근이죠. 1단계는 예시 데이터 정의입니다. 입력과 이상적인 출력 쌍을 리스트 형태로 정의합니다. 모델은 이 패턴을 모방하게 돼요. 
2단계는 메시지 구조 결합으로 [System] + [Examples] + [New Input] 순서로 전체 메시지 리스트를 구성하죠. 이게 문맥 내 학습을 유도하는 겁니다. 
3단계는 일관성 제어입니다. 예시를 통해 톤앤매너, 출력 형식, 답변 길이를 자연스럽게 제어할 수 있어요. 
팁 하나 드릴게요. Few-shot은 복잡한 지시사항을 줄글로 설명하는 것보다 2~3개의 명확한 예시를 보여주는 것이 훨씬 효과적일 때가 많습니다. 특히 json 필드 구조를 강제할 때 강력하죠.

클라우드 API 대신 로컬 환경에서 오픈소스 모델을 실행하는 방법도 알아봅시다.
세 단계 프로세스예요. 먼저 Ollama 라이브러리 사용하기 위해서 OpenAI API와 유사한 인터페이스를 제공하는 ollama 파이썬 패키지를 사용합니다. 
다음으로 코드 실행 전, 터미널에서 ollama pull llama3를 실행하여 로컬에 모델 가중치를 다운로드해야 해요. 
로컬에서 모델을 실행하면 데이터가 외부 서버로 전송되지 않아 보안이 우수하고, API 호출 비용이 전혀 발생하지 않죠. 보안 팁을 드리자면, 민감한 개인정보나 대외비 문서를 처리할 때는 로컬 모델이 가장 안전한 선택지입니다. 인터넷 연결 없이도 동작이 가능하니까요.

다음은 일관된 품질과 재사용성을 위한 체계적인 프롬프트 관리 전략을 수립합니다.
먼저, 변수화 적용입니다. Python f-string 또는 Jinja-two 템플릿 엔진을 활용하여 동적으로 프롬프트를 생성하는 거죠.
두 번째는 핵심 구성 요소 모듈화입니다. 역할, 목표, 맥락, 제약 등을 명확히 분리하죠. 
셋째, 버전 관리 및 저장소 운영입니다. Git을 활용하여 변경 이력을 추적하고 패키지 형태로 팀 내 공유해요. 
마지막으로 직관적인 디렉토리 구조로, 도메인별 분류 체계를 갖추는 겁니다.

정량적 평가를 위한 평가 항목별 자동화 규칙 및 검증 로직을 살펴봅시다.
네 가지 평가 항목이 있어요. 첫 번째는 형식 준수입니다. 지정된 json 키가 반드시 존재해야 하며, Schema Validation이나 json.loads로 검증합니다. 
둘째, 길이 제한 입니다. 요약문은 5문장 내외, 300자 이하여야 하며, len(sentences)로 체크하죠. 
셋째, 근거 인용입니다. 신뢰할 수 있는 출처나 링크가 2개 이상 포함되어야 하며, Regex Match로 확인해요. 
넷째, 사실성 확인입니다. 원본 문서의 내용과 일치하며 거짓 정보가 없어야 하는데, 이건 GPT-4를 Judge로 사용하는 LLM-based Eval로 검증합니다. 
자동화 팁을 드리자면, 단순 형식 검사는 Python 기본 라이브러리로 빠르고 저렴하게 수행하고, 사실성 검증처럼 복잡한 판단이 필요한 항목만 상위 모델을 사용하여 비용 효율적인 파이프라인을 구축하세요.

이제 A/B 테스트 스크립트를 살펴보겠습니다. 여러 모델의 성능과 비용을 비교 분석하여 최적의 모델을 선정하는 자동화 패턴입니다.
먼저, 비교 대상 모델을 리스트로 정의합니다. 경량 모델과 고성능 모델을 함께 비교하는 게 좋아요.
다음으로 리스트업된 모델들을 반복 실행합니다. 동일한 프롬프트와 messages를 사용하여 각 모델에 순차적으로 요청을 보냅니다. 일관성을 위해 temperature=0으로 설정하죠. 
마지막으로는 자동 평가 및 로깅을 위해 응답 결과를 사전에 정의한 eval_fn 함수로 채점하고, 모델별 점수와 응답 내용을 기록하는 겁니다. 
이렇게 하면 객관적인 데이터를 바탕으로 최적의 모델을 선택할 수 있어요.

AI 시스템을 실무에 배포할 때 반드시 고려해야 할 네 가지 윤리 원칙이 있습니다.
첫째, 개인정보 보호입니다.입력과 출력에서 민감 정보를 마스킹하거나 제거해야 해요.
둘째, 편향성 최소화입니다. 인종, 성별, 지역에 대한 편향이 없는지 검토하고, 다양한 테스트셋으로 검증하죠.
셋째, 환각 완화입니다. 근거 없는 주장을 방지하기 위해 출처 인용을 강제하고, 사실 확인 루프를 추가해야 합니다.
넷째, 법적 준수예요. GDPR, 저작권, 산업별 규제를 준수해야 하죠. 특히 교육 기관이나 공공 부문에서는 이러한 윤리 가이드라인이 더욱 엄격하게 적용되니 유념하시기 바랍니다.

이제 이론과 실습을 바탕으로 실제 도메인에 어떻게 적용되는지 살펴볼까요?
교육 분야에서는 학생 상담, 강의 자료 생성, 평가를 자동화합니다.
대학 행정에서는 공문 작성과 요약, 민원 응대, 일정 관리에 적용하죠.
데이터 분석에서는 EDA 가이드 제공하고 SQL 쿼리 생성이나 검증을 보조합니다.
마지막 연구에서 문헌 조사, 논문 초안 작성, 실험 설계 지원입니다. 
각 사례를 통해 프롬프트 엔지니어링이 어떻게 실무 문제를 해결하는지 구체적으로 확인하실 수 있을 겁니다.

첫 번째 사례는 학사 및 장학 규정을 안내하는 학생 상담 챗봇 구조 설계입니다.
핵심 설계 요소는 이렇습니다. 먼저 역할 정의를 합니다.
다음으로 학칙, 장학금 규정, FAQ 문서를 벡터 DB에 임베딩하여 검색 가능하게 만들죠. 
안전장치러, 확실하지 않은 정보는 "담당 부서(전화번호)로 문의하세요"라고 안내하도록 제약을 걸어요. 
마지막으로 어조 설정입니다. 친근하지만 공식적인 말투를 유지하도록 합니다. 
이렇게 설계하면 학생들이 24시간 언제든 정확한 행정 정보를 얻을 수 있죠.

두 번째 사례는 행정 공문을 자동으로 요약하고 핵심 안건을 추출하는 시스템입니다.
구조는 이렇습니다.
역할로 "당신은 대학 행정 문서 전문 테크니컬 라이터입니다."라고 설정하고, 
입력으로 PDF 또는 docx 형식의 공문을 텍스트로 추출하여 제공하죠. 
출력 형식은 json으로 문서 유형, 마감일, 핵심 3줄 요약, 담당 부서 정보를 구조화해요.
제약 조건으로는 개인정보는 마스킹 처리하고, 원문에 없는 내용은 추가하지 않도록 합니다. 

세 번째 사례는 CSV 데이터를 해석하고 EDA 가이드를 제공하는 멘토 설계입니다.
먼저 "친절하고 구체적인 데이터 분석 멘토"로서 역할을 부여하고, Python 코드 스니펫과 데이터에 대한 가정, 해석 코멘트를 함께 제공하도록 프롬프트를 작성합니다. 
이 멘토는 비전공자도 데이터 분석을 시작할 수 있도록 돕죠.

프롬프트 엔지니어링은 개인 작업이 아니라 팀 협업입니다. 생명주기를 살펴볼까요?
다섯 단계로 구성돼요. 1단계, 요구 분석을 위해 이해관계자와 함께 목표와 제약 조건을 명확히 정의합니다. 2단계는 프롬프트 설계로서, 역할-목표-제약을 구조화하고 초안을 작성하죠. 
3단계는 테스트 및 평가입니다. 루브릭 기반으로 품질을 측정하고 A/B 테스트를 수행해요. 4단계는 배포 및 모니터링으로, 프로덕션 환경에 적용하고 사용자 피드백을 수집합니다. 
마지막 5단계에서는 수집된 데이터를 바탕으로 프롬프트를 반복적으로 개선하죠. Git 기반 형상 관리를 통해 버전 이력을 추적하고, 팀원 간 코드 리뷰를 진행하는 게 핵심이에요.

문제가 발생했을 때 점검해야 할 다섯 가지 항목을 정리했습니다.
첫째, "역할, 목표가 모호하게 설정되지 않았는가?"를 살펴봅니다. "전문가"보다는 "10년 차 행정 전문가"로 구체적으로 작성하는게 낫죠. 
둘째, "예시가 명확한가?"입니다. 모호한 예시는 오히려 혼란을 야기합니다. 
셋째, "제약 조건이 상충하지 않는가?" "간결하게"와 "상세하게"를 동시에 요구하면 모델이 혼란스러워해요. 
넷째, 출력 형식이 명시적인가? json 키 이름까지 정확히 지정했는지 확인하세요. 
다섯째, Temperature 값이 적절한가? 사실 기반 작업은 0~0.3, 창의적 작업은 0.7~1.0이 적당합니다.
이 체크리스트를 따르면 대부분의 문제를 빠르게 해결할 수 있어요.

프로덕션 환경에서 비용을 절감하고 성능을 높이는 네 가지 전략입니다.
첫째, 맥락 압축입니다. 불필요한 대화 이력을 제거하고 핵심만 유지하여 토큰 수를 줄이죠. 
둘째, 모델 튜닝입니다. 반복적인 태스크는 Fine-tuning을 통해 프롬프트 길이를 대폭 단축할 수 있어요. OpenAI의 경우 gpt-3.5-turbo를 튜닝하면 비용이 50% 이상 절감됩니다. 
셋째, 시스템 최적화는 캐싱 메커니즘을 도입하여 동일한 질문에 대한 재호출을 방지하죠. 
넷째, 모델 앙상블로 간단한 태스크는 경량 모델로, 복잡한 추론은 고성능 모델로 라우팅하는 전략이에요. 
이렇게 하면 품질을 유지하면서도 비용을 줄일 수 있습니다.

종합 실습 과제를 소개합니다. 행정 공문 지능형 요약기를 제작하는 겁니다.
요구사항은 이래요. 공문 PDF를 입력받아 문서 유형, 마감일, 핵심 요약, 담당 부서를 json으로 출력해야 합니다. 
Python, OpenAI API, PyPDF2 또는 pdfplumber를 사용하죠. 평가 기준은 형식 준수, 완전성, 정확성, 안전성으로 평가합니다. 실행 가능한 Python 스크립트, 테스트셋 3개와 결과 json 파일, 그리고 설계 문서를 제출하시면 됩니다. 이 과제를 통해 오늘 배운 모든 개념을 실전에 적용해보실 거예요.

Jinja2와 OpenAI API를 결합한 종합 실습 코드 구조를 살펴봅시다.
구조는 이렇습니다. Jinja2 Environment를 설정하고 프롬프트 템플릿 파일을 로드하죠. 
다음으로 변수 바인딩. 동적 변수를 템플릿에 주입합니다. 그리고 렌더링된 프롬프트를 OpenAI API에 전송하고 응답을 받아요.
최종적으로 생성된 텍스트를 평가 함수를 통해 응답이 루브릭을 충족하는지 확인합니다. 
결과에 대해 성공, 실패 여부와 함께 데이터베이스나 파일에 저장합니다. 
이 스켈레톤을 기반으로 여러분만의 자동화 파이프라인을 구축할 수 있어요.

심화 학습을 위한 리소스를 정리했습니다.
세 가지 카테고리예요. 공식 가이드는 OpenAI와 Anthropic의 공식 홈페이지를 참고하세요. 
심화 학습 자료는 Chain-of-Thought, ReAct, Tree of Thoughts 논문을 읽어보시면 좋습니다.
로컬 LLM 구축 가이드는 Ollama 공식 문서와 Hugging Face Transformers 라이브러리를 활용하여 온프레미스 환경을 구축할 수 있어요.
행정 문서 표준과 용어집은 프롬프트 작성 시 System Persona와 Few-shot 예제로 활용하기 적합합니다.

오늘 우리가 함께 여행한 내용을 정리해볼까요?
핵심 개념 세 가지를 복습합니다. 첫째, 역할 정의 입니다. 명확한 페르소나가 일관된 품질을 보장해요. 
둘째,조건 설정입니다. 출력 형식과 제약 조건이 정교한 제어를 가능하게 하죠. 
셋째, 7단계 프레임워크를 통해 재현성을 확보합니다. 

다음 단계는 이렇습니다. 템플릿 라이브러리를 구축하여 조직 내 공유하세요. 테스트셋을 확보하여 지속적으로 품질을 검증하고, 실무 프로젝트에 점진적으로 적용하며, 커뮤니티에 참여하여 최신 트렌드를 습득하는 겁니다. 프롬프트 엔지니어링은 기술이 아니라 사고방식이에요.

오늘 우리는 프롬프트 엔지니어링의 핵심 원리부터 Python 실습, 그리고 실제 도메인 적용 사례까지 폭넓게 다뤘어요.
여러분의 실무 현장에서 AI가 진정한 생산성 도구가 되기를 바랍니다. 감사합니다!
