생성형 AI의 기술적 원리 - 강의 스크립트 (45분)
슬라이드 1: 커버
안녕하세요, 여러분. 국립창원대학교 PRU 재직자 교육 과정에 오신 것을 환영합니다.

오늘은 생성형 AI의 기술적 원리에 대해 함께 알아보는 시간을 갖겠습니다. ChatGPT나 Claude 같은 대화형 AI가 어떻게 작동하는지, 그 내부 메커니즘을 깊이 있게 다뤄볼 거예요.

슬라이드 2: 목차
오늘 교육은 크게 두 파트로 나뉩니다. 첫 번째 파트에서는 LLM이 단어를 생성하는 방식을 살펴보겠습니다.

토큰화부터 시작해서 트랜스포머 아키텍처, 그리고 실제로 어떻게 다음 단어를 예측하는지까지 전체 파이프라인을 따라가볼 거예요. 두 번째 파트에서는 확률 기반 언어 예측 모델의 관점에서 LLM을 분석하고, 실무 적용 방법까지 다루겠습니다.

슬라이드 3: 학습 목표
본 과정을 통해 여러분이 달성하실 핵심 목표를 먼저 확인하고 시작하겠습니다. 첫째, 토큰화와 임베딩, 트랜스포머의 기본 구조를 이해하게 됩니다.

둘째, Next Token Prediction과 Softmax 수식의 의미를 파악하고, 셋째로 다양한 디코딩 전략을 비교할 수 있게 되죠. 넷째, 확률적 언어 모델 관점에서 LLM의 동작을 해석할 수 있으며, 마지막으로 실무에서 프롬프트 설계와 하이퍼파라미터 튜닝을 적용할 수 있게 됩니다.

슬라이드 4: 섹션 1 시작
자, 그럼 첫 번째 섹션을 시작하겠습니다. LLM이 단어를 생성하는 방식이에요.

거대 언어 모델이 사용자의 입력을 받아서 적절한 답변을 만들어내기까지, 내부에서는 정확히 어떤 일이 벌어질까요? 토큰화부터 샘플링까지, 생성 메커니즘을 단계별로 해부해보겠습니다.

슬라이드 5: 텍스트 생성 문제 정의
언어 모델링의 핵심 목표는 명확합니다. 주어진 문맥을 바탕으로 다음에 올 토큰을 가장 그럴듯하게 예측하는 것이죠.

이를 자기회귀 방식이라고 부르는데요, 앞에 나온 토큰들에 조건부로 다음 토큰을 생성합니다. 이 단순한 원리가 요약, 번역, 코드 생성 등 다양한 업무 자동화의 기반이 되는 거예요.

슬라이드 6: 토큰과 토크나이제이션
LLM이 텍스트를 이해하는 가장 기초적인 단위가 바로 토큰입니다. 토큰은 단어나 서브워드, 심지어 바이트 단위의 조각일 수 있어요.

예를 들어 "안녕하세요"라는 단어는 [안, 녕, 하, 세, 요]처럼 나뉘거나 서브워드로 조합될 수 있죠. 토크나이저를 설계할 때는 어휘 크기, 희귀어 처리 방법, 특히 한국어의 조사나 합성어를 어떻게 다룰지가 중요한 고려사항입니다.

슬라이드 7: 토크나이저 방법 비교
토크나이저 방법을 비교해볼까요. 왼쪽에는 BPE, 즉 Byte Pair Encoding 방식이 있습니다.

빈도가 높은 문자 쌍을 병합해서 단위를 확장하는 방식이에요. 희귀어에 강인하고 어휘를 효율적으로 관리할 수 있죠. 오른쪽에는 WordPiece와 Unigram 방식이 있는데, WordPiece는 확률적 분해 기준을 사용하고, Unigram은 후보 어휘 집합을 확률적으로 최적화합니다.

슬라이드 8: 임베딩과 벡터 표현
토큰이 결정되면 다음 단계는 임베딩입니다. 이산적인 토큰 ID를 고정 차원의 연속 벡터로 변환하는 거예요.

이 테이블을 조회하는 방식으로 작동하며, 의미적으로 유사한 단어들이 벡터 공간에서 가까이 위치하게 됩니다. 트랜스포머 블록을 거치면서 문맥적 표현이 더욱 강화되고요, 학습 시 임베딩과 출력 가중치를 공유하면 일반화 성능이 향상되는 효과가 있습니다.

슬라이드 9: 트랜스포머 기본 구조
트랜스포머의 기본 구조를 살펴보죠. 하나의 블록은 멀티헤드 어텐션과 MLP로 구성됩니다.

여기에 레이어 정규화와 잔차 연결이 더해지죠. 병렬 처리가 가능해서 장기 의존성 학습이 효과적이에요. GPT 계열 모델은 디코더만 사용하는 구조인데, 마스크드 어텐션으로 미래의 토큰을 가려서 학습합니다.

슬라이드 10: 어텐션의 핵심 Q, K, V
어텐션 메커니즘의 핵심 아이디어를 설명드리겠습니다. 현재 토큰이 Query가 되어서 과거 토큰들의 Key와 비교하는 거예요.

유사도를 계산한 다음 Value의 가중합으로 출력을 만들어냅니다. 직관적으로 말하면, 연관성이 높은 위치에 더 큰 가중치를 주는 방식이죠.

슬라이드 11: 멀티헤드 어텐션 시각화
이 히트맵은 멀티헤드 어텐션의 패턴을 보여주는 시각화입니다. 문장 내 토큰들이 서로에게 얼마나 집중하는지 색깔로 나타낸 거예요.

흥미로운 점은 각 헤드가 서로 다른 관계를 포착한다는 겁니다. 어떤 헤드는 문법적 관계를, 어떤 헤드는 긴 거리 의존성을, 또 다른 헤드는 구문 구조를 학습하죠. 이렇게 여러 헤드를 결합하면 표현력이 크게 강화됩니다.

슬라이드 12: 포지셔널 인코딩
트랜스포머는 병렬 처리를 하기 때문에 순서 정보가 없습니다. 그래서 포지셔널 인코딩으로 위치 신호를 인위적으로 주입해요.

sin과 cos 함수 기반의 신호를 사용하는데, 낮은 주파수는 긴 거리를, 높은 주파수는 짧은 거리의 패턴을 인코딩합니다. 이를 통해 위치 불변성과 외삽 성질을 얻을 수 있죠.

슬라이드 13: 디코더와 마스크드 어텐션
디코더는 미래 토큰을 보지 않도록 마스크를 적용합니다. 학습 중에 정답을 미리 보면 안 되니까요.

한 단계씩 다음 토큰의 확률 분포를 산출하고, 샘플링으로 선택한 다음, 그걸 다시 컨텍스트에 추가하는 방식으로 문장을 확장해나갑니다.

슬라이드 14: Next Token Prediction
LLM 학습의 핵심 목적 함수입니다. 각 시점 t에서 log P(x_t | x_<t)를 최대화하는 거예요.

손실 함수로는 크로스엔트로피를 사용하는데, 정답 토큰의 음의 로그 확률을 최소화하는 방식이죠. 이 간단한 원리로 문맥에 조건화된 자연스러운 문장 생성이 가능해집니다.

슬라이드 15: Softmax와 Temperature
모델의 원시 출력값인 로짓을 확률로 변환하는 게 Softmax입니다. 여기에 Temperature 파라미터 T를 곱해서 분포를 조절할 수 있어요.

T가 높으면 분포가 평탄해져서 더 랜덤하고, T가 낮으면 날카로워져서 결정적이 됩니다. 이 미세 조정으로 창의성과 안정성의 균형을 맞출 수 있죠.

슬라이드 16: 디코딩 전략 개요
디코딩 전략을 크게 두 가지로 나눌 수 있습니다. 왼쪽은 Greedy나 Beam Search 같은 결정적 방식이에요.

Greedy는 항상 최고 확률을 선택해서 빠르지만 다양성이 낮습니다. Beam Search는 여러 후보를 동시에 탐색해서 품질은 높지만 속도가 느려지죠. 오른쪽의 Sampling 방식은 확률적으로 선택해서 다양성과 창의성을 확보합니다.

슬라이드 17: Top-k, Top-p, Temperature 비교
생성 다양성을 조절하는 세 가지 핵심 방법입니다. Top-k는 상위 k개 후보만 재정규화해서 샘플링하는 거예요.

k가 1이면 Greedy와 동일하죠. Top-p는 누적 확률이 p까지인 후보만 포함하는 방식인데, 문맥에 적응적이라는 장점이 있습니다. Temperature는 분포 전체의 날카로움을 제어하고요.

슬라이드 18: 반복/루프 방지와 제약
생성 품질을 유지하고 무한 반복을 방지하는 기법들입니다. N-gram penalty로 중복된 구문을 억제할 수 있어요.

repetition penalty로 같은 토큰이 반복되는 걸 막고, presence와 frequency penalty로 더 세밀하게 조절할 수 있죠. 금지 토큰 리스트나 길이 제약도 실무에서 자주 사용됩니다.

슬라이드 19: LLM 생성 루프 한 눈에 보기
자, 전체 파이프라인을 한눈에 정리해보겠습니다. 1단계 토큰화, 2단계 임베딩과 포지션 추가, 3단계 어텐션과 MLP 통과, 4단계 로짓 계산, 5단계 Softmax와 샘플링이에요.

이 과정이 반복되면서 문장이 완성됩니다. 각 단계에서 KV 캐시를 활용하면 추론 속도를 크게 향상시킬 수 있죠.

슬라이드 20: 프롬프트 생성 시뮬레이션
실습 예제를 살펴보겠습니다. Step 1에서 프롬프트를 입력하고 토큰화합니다.

Step 2에서 로짓 분포를 확인하고 상위 후보들을 살펴보죠. Step 3에서 Temperature, Top-k, Top-p를 바꿔가며 샘플링하고, Step 4에서 생성 결과를 비교 분석합니다. 이 과정을 직접 해보시면 파라미터가 결과에 미치는 영향을 체감하실 수 있을 거예요.

슬라이드 21: 섹션 2 시작
이제 두 번째 섹션으로 넘어가겠습니다. 확률 기반 언어 예측 모델이라는 관점이에요.

언어 모델을 확률 분포로 해석하고, Chain Rule, 평가 지표, 최적화 방법, 그리고 현재의 한계와 최신 기법들을 함께 살펴보겠습니다.

슬라이드 22: 언어 모델 계보
언어 모델의 발전 과정을 간단히 정리하면 이렇습니다. 처음에는 N-gram 같은 카운트 기반 모델이 있었어요.

그다음 RNN과 LSTM이 등장해서 순환 신경망으로 장기 의존성을 학습했죠. 그리고 현재의 Transformer가 병렬 어텐션 메커니즘으로 장기 의존성과 병렬화, 표현력 모두를 크게 향상시켰습니다.

슬라이드 23: 자기회귀 vs 마스크드 LM vs Seq2Seq
언어 모델 아키텍처를 세 가지 유형으로 비교해보겠습니다. 자기회귀 모델은 이전 토큰들로 다음 토큰을 예측하죠.

GPT 계열이 여기 속하고, 텍스트 생성에 최적화되어 있습니다. 마스크드 LM은 문장 중간의 가려진 토큰을 복원하는 방식이에요. BERT가 대표적이고, 깊은 이해와 분류 태스크에 강합니다. Seq2Seq는 입력을 압축한 후 다른 형태로 변환하는 구조로, 번역이나 요약에 특화되어 있죠.

슬라이드 24: 확률 분해와 Chain Rule
문장의 생성 확률을 수학적으로 표현하면 이렇습니다. P(x1…xT)는 각 시점의 조건부 확률의 곱으로 분해되죠.

로그를 취하면 합으로 바뀌고, 이걸 최대화하는 게 학습 목표입니다. 결국 조건부 분포를 잘 근사하는 것이 언어 모델의 핵심이에요.

슬라이드 25: 조건부확률 직관
조건부 확률을 직관적으로 이해해볼까요. "오늘 날씨가"라는 맥락 다음에는 "좋아요", "흐려요", "맑아요" 같은 후보들이 각기 다른 확률로 나타납니다.

도메인이나 스타일, 프롬프트 구조에 따라 이 분포가 달라지죠. 학습 데이터의 분포가 사전 확률처럼 작용하는 겁니다.

슬라이드 26: 평가지표 Perplexity
모델의 성능을 평가하는 핵심 지표가 Perplexity입니다. PPL이 낮을수록 모델이 다음 토큰을 더 확신 있게 예측한다는 의미예요.

불확실성이 낮다는 거죠. 실무에서는 PPL만으로 판단하기보다는 작업별 정확도나 인간 평가와 함께 종합적으로 봐야 합니다.

슬라이드 27: Temperature에 따른 문장 변화
Temperature 변화에 따른 실제 생성 결과를 비교해보겠습니다. T가 0.2처럼 낮으면 일관되고 사실 중심적인 문장이 나와요.

T가 1.8처럼 높으면 창의적이고 다양하지만, 일관성이 저하될 수 있습니다. 목적에 맞게 T를 조절하는 게 중요하죠.

슬라이드 28: 추론 최적화 전략
실전에서 LLM 추론 속도를 높이는 전략들입니다. KV 캐시를 재사용하면 O(L) 수준의 증분 추론이 가능해요.

스페큘러티브 디코딩은 작은 모델로 초안을 만들고 큰 모델로 검증하는 방식으로 지연을 줄입니다. FlashAttention 같은 메모리와 연산 최적화 기법도 많이 활용되고 있죠.

슬라이드 29: 안전/가드레일과 디코딩 트레이드오프
안전성 확보와 성능 사이의 균형 문제를 다뤄보겠습니다. 안전 필터나 정책을 적용하면 다양성이 감소할 수 있어요.

Temperature나 Top-p를 보수적으로 설정하면 리스크는 완화되지만 창의성이 떨어질 수 있죠. 도메인 규정 준수와 품질의 균형을 찾는 게 실무자의 과제입니다.

슬라이드 30: 도메인 적용 팁
세 가지 산업 분야의 적용 사례를 소개합니다. 제조 분야에서는 공정 로그 요약이나 원인 가설 생성에 활용할 수 있어요.

프롬프트에 데이터 스키마와 목표, 제약을 명확히 명시해야 합니다. 교육 분야는 강의안 생성이나 수준별 콘텐츠 제작이 가능하죠. 학습 목표와 난이도, 톤을 지정하면 효과적입니다. 공공 분야는 민원 응답 초안이나 정책 요약에 쓰이는데, 금지 주제와 근거 출처를 요구하는 게 중요해요.

슬라이드 31: 한계와 도전과제
LLM의 한계도 솔직히 짚고 넘어가야겠죠. Softmax 병목 문제로 표현력이 제한될 수 있고, 긴 컨텍스트를 다룰 때 비용과 정보 손실 이슈가 있습니다.

노출 편향, 즉 학습과 추론의 분포 차이 문제도 있고요. 할루시네이션, 그러니까 사실이 아닌 내용을 그럴듯하게 생성하는 현상도 여전한 과제입니다. 데이터나 정책 업데이트가 지연되는 것도 실무에서 고민해야 할 지점이죠.

슬라이드 32: 최신 동향 브리핑
최신 연구 동향을 간단히 소개하겠습니다. Mixture-of-Experts, 즉 MoE 구조로 효율성과 스케일을 동시에 향상시키는 시도가 있어요.

Multi-Token Prediction으로 속도와 일관성을 개선하려는 연구도 진행 중입니다. 장문 컨텍스트 처리, RAG나 툴 사용 통합, 그리고 안전성 강화는 현재 가장 활발한 영역이죠.

슬라이드 33: 실습 과제 안내
실습 과제를 안내해드리겠습니다. Step 1에서 베이스라인을 설정하세요.

Temperature 1.0, Top-p 0.9, 반복 페널티 1.0으로 시작합니다. Step 2에서 각 파라미터를 변화시키며 품질을 비교하고, Step 3에서 금지 토큰이나 길이 제한을 적용해보세요. Step 4에서 결과를 기록하고 관찰 내용을 정리하면 됩니다.

슬라이드 34: 요약 및 Q&A
오늘 배운 내용을 정리하겠습니다. 핵심은 LLM 생성이 확률 분포 샘플링 과정이라는 거예요.

설계 레버로는 토크나이저, 어텐션, 소프트맥스, 디코딩 파라미터가 있고, 실무에서는 품질과 속도, 안전성의 균형을 튜닝하는 게 중요합니다. 이제 질문을 받겠습니다. 강의 내용 중 궁금한 점이나 실무 적용에 대한 고민을 자유롭게 나눠주세요.
