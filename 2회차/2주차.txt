📝 생성형 AI의 기술적 원리 - 발표 스크립트 (45분)
슬라이드 1: 표지 (30초)
안녕하세요, 여러분. 오늘 국립창원대학교 PRU 재직자 교육 과정에 함께하게 되어 반갑습니다. 오늘은 '생성형 AI의 기술적 원리'라는 주제로 여러분과 함께 시간을 보내려고 합니다.

최근 챗GPT를 비롯한 다양한 생성형 AI 서비스들이 우리 일상에 깊숙이 들어왔죠. 그런데 이 기술들이 실제로 어떻게 작동하는지, 그 내부 메커니즘을 이해하는 것이 매우 중요해졌습니다.

슬라이드 2: AGENDA (1분)
오늘 교육은 크게 세 개의 파트로 구성되어 있습니다. 먼저 PART A에서는 LLM이 단어를 생성하는 방식에 대해 살펴볼 건데요. 토큰화라는 개념부터 시작해서 트랜스포머 구조, 그리고 어텐션 메커니즘까지 차근차근 알아보겠습니다.

PART B에서는 확률 기반 언어 예측 모델의 원리를 다룹니다. Next Token Prediction이라는 핵심 개념과 함께, 실제로 AI가 어떤 확률 분포를 기반으로 다음 단어를 선택하는지 수식과 함께 이해해보겠습니다. 그리고 마지막 PART C에서는 실습과 함께 최신 기술 동향까지 살펴보는 시간을 가질 예정입니다.

슬라이드 3: 학습 목표 (1분)
오늘 교육을 통해 여러분이 달성하게 될 목표들을 먼저 짚고 넘어가겠습니다. 첫째, LLM의 기본 구조를 명확히 이해하시게 될 겁니다. 단순히 "AI가 답변을 준다"는 표면적 이해를 넘어서, 그 내부에서 어떤 계산이 일어나는지 아시게 될 거예요.

둘째는 생성 원리를 수식으로 해석하는 능력입니다. 수식이 조금 나오긴 하지만 어렵지 않으니 걱정하지 마세요. 셋째, 다양한 디코딩 전략들을 비교 분석할 수 있게 되고요. 마지막으로 확률적 관점에서 언어 모델을 해석하는 통찰력을 키우시게 될 겁니다.

슬라이드 4: 생성 메커니즘 개요 (1분 30초)
자, 그럼 본격적으로 시작해볼까요? LLM이 텍스트를 생성하는 과정은 크게 네 단계로 요약할 수 있습니다.

첫 번째는 토큰화입니다. 우리가 입력한 문장을 AI가 이해할 수 있는 작은 단위로 쪼개는 거죠. 두 번째는 어텐션 단계인데, 이 과정에서 각 토큰들 간의 관계를 파악합니다. 세 번째는 로짓 계산입니다. 모델이 다음에 올 가능성이 있는 모든 단어들에 대해 점수를 매기는 과정이에요. 마지막으로 샘플링 단계에서 실제로 하나의 토큰을 선택하게 됩니다.

이 네 단계가 계속 반복되면서 우리가 보는 긴 문장이 만들어지는 거예요. 마치 레고 블록을 하나씩 쌓아올리듯이 말이죠.

슬라이드 5: 언어 모델링의 정의 (1분 30초)
언어 모델링의 핵심은 바로 이 수식으로 표현할 수 있습니다. P(x_t)는 조건부 확률인데요, 쉽게 말해 "지금까지 나온 단어들이 주어졌을 때, 다음 단어가 나올 확률"을 의미합니다.

이걸 자기회귀 방식, 영어로는 Autoregressive라고 부릅니다. 왜 자기회귀냐면, 자기 자신이 이전에 생성한 결과를 다시 입력으로 받아서 다음 단어를 예측하거든요. 마치 체인처럼 연결되는 거죠. 첫 단어를 예측하고, 그 단어를 포함해서 두 번째 단어를 예측하고, 또 그걸 포함해서 세 번째를 예측하는 식입니다.

이 방식의 장점은 모델이 문맥을 계속 유지하면서 일관된 문장을 생성할 수 있다는 점입니다.

슬라이드 6: 토큰화 (1분 30초)
토큰화를 좀 더 자세히 살펴볼까요? 예를 들어 "생성형 AI의 원리"라는 문장이 있다고 해봅시다. 우리 눈에는 그냥 하나의 문장으로 보이지만, AI에게는 이게 여러 개의 토큰으로 쪼개집니다.

'생성', '형', 'AI', '의', '원리' 이런 식으로 나뉘는 거죠. 여기서 중요한 건 단어 단위가 아니라 서브워드 단위라는 점입니다. '생성형'이라는 단어도 '생성'과 '형'으로 나뉘거든요.

이렇게 하는 이유는 효율성 때문입니다. 모든 가능한 단어를 다 외우게 하는 것보다, 작은 단위로 쪼개서 조합하게 하는 게 훨씬 효율적이거든요. 마치 한글의 자음과 모음으로 모든 글자를 만들 수 있는 것처럼요.

슬라이드 7: 토크나이저 비교 (1분 30초)
토크나이저에도 여러 종류가 있습니다. 대표적으로 BPE 방식과 WordPiece, Unigram 방식이 있는데요.

BPE는 빈도 기반입니다. 데이터에서 자주 같이 나오는 문자 쌍을 찾아서 하나로 합치는 방식이죠. GPT 시리즈가 이 방식을 사용합니다. 반면 WordPiece나 Unigram은 확률 기반입니다. 어떤 조합이 통계적으로 가장 합리적인지를 계산해서 선택하는 거예요. BERT나 T5 같은 모델들이 이 방식을 씁니다.

각 방식마다 장단점이 있지만, 최근에는 BPE가 가장 많이 사용되고 있습니다. 구현이 상대적으로 단순하면서도 성능이 우수하거든요.

슬라이드 8: 임베딩 (1분 30초)
토큰화가 끝나면 이제 임베딩 단계로 넘어갑니다. 토큰 ID는 그냥 숫자예요. 예를 들어 '생성'이 1234번, 'AI'가 5678번 이런 식이죠. 그런데 이 숫자 자체로는 의미를 담을 수 없습니다.

그래서 각 토큰을 고차원의 벡터로 변환합니다. 보통 수백에서 수천 차원의 벡터로 표현되는데요. 이 벡터 공간 안에서 비슷한 의미를 가진 단어들은 가까운 위치에 배치됩니다.

유명한 예시가 있죠. "왕 - 남자 + 여자 = 여왕"이라는 관계가 벡터 공간에서 실제로 성립합니다. 이게 바로 임베딩의 힘입니다. 단순한 기호를 의미 있는 수학적 표현으로 바꿔주는 거죠.

슬라이드 9: 트랜스포머 구조 (2분)
이제 본격적으로 트랜스포머 구조를 살펴보겠습니다. GPT는 디코더 온리 구조를 사용하는데요, 이게 무슨 뜻이냐면 인코더 없이 디코더만으로 구성되어 있다는 뜻입니다.

핵심은 마스크드 어텐션입니다. 이 메커니즘을 통해 모델은 미래의 토큰을 볼 수 없게 제한됩니다. 왜 그럴까요? 학습할 때 치팅을 방지하기 위해서입니다. 만약 답을 미리 볼 수 있다면, 모델이 제대로 학습되지 않겠죠.

또 하나의 큰 장점은 병렬 처리입니다. 과거 RNN 방식은 순차적으로 처리해야 했지만, 트랜스포머는 한 번에 모든 위치를 동시에 계산할 수 있습니다. 이게 바로 트랜스포머가 혁신적이었던 이유입니다. 속도가 비교할 수 없을 정도로 빨라졌거든요.

슬라이드 10: 어텐션 메커니즘 (2분)
어텐션 메커니즘은 이 모든 것의 핵심입니다. 조금 복잡하지만 천천히 설명드리겠습니다.

세 가지 요소가 있습니다. Query는 "내가 찾고 싶은 정보"입니다. Key는 "각 단어의 식별자"고요. Value는 "실제 내용물"이죠. 도서관에 비유하면, Query는 검색어, Key는 책 제목, Value는 책 내용이라고 생각하시면 됩니다.

어텐션 계산 과정은 이렇습니다. Query와 Key를 내적해서 유사도를 계산합니다. 그 다음 소프트맥스를 취해서 확률 분포로 만들어요. 마지막으로 이 확률을 가중치로 사용해 Value들을 가중합산합니다. 결과적으로 현재 위치에서 어떤 단어에 주목해야 하는지 자동으로 학습하게 되는 거죠.

슬라이드 11: 멀티헤드 어텐션 시각화 (1분 30초)
실제 예시를 보면 더 명확하게 이해가 됩니다. 이 히트맵을 보시면 'it'이라는 단어가 'animal'을 강하게 가리키고 있는 걸 볼 수 있죠.

이게 바로 어텐션의 힘입니다. 대명사가 무엇을 지칭하는지, 문맥상 어떤 단어와 연결되어야 하는지를 모델이 스스로 파악합니다. 사람이 일일이 규칙을 만들어주지 않아도 데이터로부터 학습하는 거예요.

멀티헤드라는 건 이런 어텐션을 여러 개 병렬로 수행한다는 뜻입니다. 각 헤드마다 다른 관점에서 관계를 포착하게 되죠. 한 헤드는 문법적 관계를, 다른 헤드는 의미적 관계를 학습하는 식으로요.

슬라이드 12: 포지셔널 인코딩 (1분 30초)
그런데 여기서 문제가 하나 있습니다. 트랜스포머는 모든 위치를 동시에 처리하기 때문에, 단어의 순서 정보가 사라집니다. "개가 고양이를 쫓는다"와 "고양이가 개를 쫓는다"가 구별이 안 되는 거죠.

이 문제를 해결하기 위해 포지셔널 인코딩을 추가합니다. 사인과 코사인 함수를 사용해서 각 위치마다 고유한 패턴을 만들어내는 거예요. 이 패턴이 임베딩 벡터에 더해지면서, 모델이 순서 정보를 인식할 수 있게 됩니다.

수학적으로 보면 주기가 다른 삼각함수들을 조합하는데요, 이렇게 하면 위치 간의 상대적 거리도 표현할 수 있게 됩니다. 상당히 영리한 방법이죠.

슬라이드 13: 마스크드 어텐션 (1분 30초)
조금 전에 언급했던 마스크드 어텐션을 좀 더 자세히 볼까요? 이건 인과성, 즉 Causality를 보장하기 위한 장치입니다.

학습할 때 모델은 문장 전체를 한 번에 봅니다. 하지만 각 위치에서 예측할 때는 그 위치보다 뒤에 있는 토큰들을 봐서는 안 되겠죠. 그래서 미래 토큰들에 대한 어텐션을 마이너스 무한대로 마스킹합니다. 소프트맥스를 거치면 이 값들은 0이 되어버려서, 사실상 미래 정보가 차단되는 거예요.

이렇게 하면 모델이 추론할 때와 동일한 조건에서 학습하게 됩니다. 정직하게 왼쪽에서 오른쪽으로만 정보를 사용하도록 강제하는 거죠.

슬라이드 14: Next Token Prediction (2분)
이제 학습의 핵심 원리인 Next Token Prediction을 살펴보겠습니다. LLM 학습의 본질은 다음 토큰의 등장 확률을 최대화하는 것입니다.

손실 함수를 보시면 크로스엔트로피가 사용되고 있죠. 이게 뭐냐면, 모델이 예측한 확률 분포와 정답 분포 사이의 차이를 측정하는 겁니다. 이 차이가 작을수록, 즉 손실이 작을수록 모델이 잘 학습된 거예요.

수십억 개의 문장으로 학습하면서 이 손실을 계속 줄여나갑니다. 결과적으로 모델은 "이 문맥 다음에는 이런 단어가 올 확률이 높다"는 패턴을 내재화하게 되는 거죠. 이게 바로 GPT가 그럴듯한 문장을 생성할 수 있는 이유입니다.

슬라이드 15: Softmax & Temperature (2분)
로짓에서 실제 확률로 변환하는 과정이 바로 소프트맥스입니다. 그런데 여기서 Temperature라는 중요한 파라미터가 등장합니다.

Temperature를 낮추면 확률 분포가 날카로워집니다. 가장 높은 확률을 가진 토큰이 더 두드러지게 되죠. 반대로 Temperature를 높이면 분포가 평평해집니다. 확률이 고르게 분산되는 거예요.

실무적으로 이게 왜 중요하냐면, 생성 스타일을 조절할 수 있기 때문입니다. 낮은 Temperature는 보수적이고 예측 가능한 출력을 만들어냅니다. 높은 Temperature는 창의적이지만 때로는 이상한 결과를 낼 수 있죠. 상황에 따라 적절히 조절해야 합니다.

슬라이드 16: 디코딩 전략 개요 (1분 30초)
확률 분포를 얻었으면 이제 실제로 토큰을 선택해야 합니다. 여기에는 크게 두 가지 방식이 있습니다.

결정적 방식은 Greedy나 Beam Search처럼 항상 같은 결과를 내놓습니다. 확률이 가장 높은 경로를 선택하는 거죠. 장점은 안정적이라는 것이고, 단점은 다양성이 떨어진다는 겁니다.

확률적 방식은 Sampling 기법들인데요, 매번 다른 결과가 나올 수 있습니다. 확률 분포에서 무작위로 샘플링하기 때문이죠. 창의적인 텍스트 생성에는 이 방식이 더 적합합니다. 각 방식의 장단점을 이해하고 상황에 맞게 선택하는 게 중요합니다.

슬라이드 17: Top-k, Top-p (2분)
확률적 샘플링에도 여러 기법이 있습니다. 대표적인 게 Top-k와 Top-p죠.

Top-k는 간단합니다. 확률이 높은 상위 k개 토큰 중에서만 선택하는 거예요. 예를 들어 k=5면 상위 5개 후보 중 하나를 고르는 겁니다. 문제는 k가 고정되어 있다는 점입니다. 어떤 상황에서는 5개가 너무 많을 수도, 너무 적을 수도 있거든요.

Top-p는 이 문제를 해결합니다. 누적 확률이 p를 넘을 때까지 후보를 추가하는 방식이에요. 만약 p=0.9라면, 확률을 높은 순서대로 더해가다가 90%가 되는 순간 멈추는 겁니다. 그래서 상황에 따라 후보 개수가 동적으로 변합니다. 확실한 문맥에서는 적게, 애매한 문맥에서는 많이 선택하는 거죠.

슬라이드 18: 반복 방지 제약 (1분 30초)
실제로 텍스트를 생성하다 보면 같은 말을 계속 반복하는 문제가 생길 수 있습니다. 이를 방지하기 위한 여러 기법들이 있습니다.

N-gram Penalty는 같은 단어 조합이 반복되면 확률을 깎아내립니다. Repetition Penalty는 이미 나온 토큰의 확률을 감소시키고요. Length Penalty는 문장이 너무 길거나 짧아지지 않도록 조절합니다.

이런 제약들을 적절히 조합하면 훨씬 자연스럽고 읽기 좋은 텍스트를 생성할 수 있습니다. 하지만 너무 강하게 적용하면 오히려 부자연스러워질 수 있으니 균형이 중요합니다.

슬라이드 19: 생성 루프 전체도 (2분)
지금까지 배운 모든 내용을 종합해볼까요? 생성 과정은 다섯 단계가 계속 반복됩니다.

입력 토큰화부터 시작해서, 임베딩 변환, 트랜스포머 레이어 통과, 로짓 계산, 그리고 샘플링까지. 샘플링된 토큰은 다시 입력에 추가되고, 이 과정이 끝나는 토큰이 나올 때까지 반복됩니다.

여기서 중요한 최적화 기법이 KV Cache입니다. 매번 처음부터 다시 계산하는 게 아니라, 이전에 계산한 Key와 Value를 저장해두고 재사용하는 거예요. 이렇게 하면 속도가 엄청나게 빨라집니다. 특히 긴 문장을 생성할 때 효과가 큽니다.

슬라이드 20: 생성 시뮬레이션 (1분 30초)
실제 예시로 이해해봅시다. "오늘 날씨가 정말" 이라는 입력이 들어왔다고 가정하겠습니다.

모델은 다음 단어 후보들을 찾습니다. "좋네요", "춥네요", "더워요" 등이 있겠죠. 각각에 대해 확률을 계산합니다. 현재 문맥을 고려했을 때 "좋네요"가 가장 높은 확률을 가진다고 해봅시다.

샘플링 전략에 따라 "좋네요"가 선택될 가능성이 크지만, Top-p 샘플링을 사용하면 다른 후보도 선택될 수 있습니다. 이렇게 한 토큰이 생성되면 "오늘 날씨가 정말 좋네요"가 되고, 이제 이 전체 문맥을 바탕으로 다음 토큰을 예측하는 과정이 반복됩니다.

슬라이드 21: PART B 시작 (30초)
자, 이제 PART B로 넘어가겠습니다. 지금까지는 메커니즘을 봤다면, 이제는 그 이면의 확률과 최적화 이론을 좀 더 깊이 있게 다룰 예정입니다.

수학적 배경을 이해하면 실무에서 파라미터를 조절할 때 훨씬 더 효과적으로 대응할 수 있습니다.

슬라이드 22: 언어 모델 계보 (1분 30초)
언어 모델의 역사를 간단히 살펴보면, 초기에는 N-gram 모델이 사용됐습니다. 단순히 단어의 빈도를 세는 방식이었죠. 그 다음 RNN과 LSTM이 등장하면서 순차적 패턴을 학습할 수 있게 됐습니다.

하지만 진짜 혁명은 2017년 트랜스포머의 등장입니다. 병렬 처리가 가능해지면서 대규모 학습이 현실화됐고, 그 결과 GPT 같은 거대 언어 모델이 탄생하게 된 거죠.

이 계보를 이해하는 게 중요한 이유는, 각 세대마다 해결하려 했던 문제와 한계를 알 수 있기 때문입니다. 트랜스포머도 완벽하진 않습니다. 여전히 개선의 여지가 많죠.

슬라이드 23: 아키텍처 유형 (1분 30초)
트랜스포머 기반 모델에도 여러 유형이 있습니다. Autoregressive 방식의 GPT는 왼쪽에서 오른쪽으로 생성하는 데 특화되어 있습니다. 텍스트 생성이 주 목적이죠.

Masked LM 방식의 BERT는 양방향으로 문맥을 이해합니다. 문장의 빈칸을 채우는 식으로 학습하기 때문에 이해 능력이 뛰어납니다. 검색이나 분류 같은 태스크에 적합하고요.

Seq2Seq 방식의 T5는 둘 다 갖춘 구조입니다. 번역이나 요약처럼 입력과 출력이 모두 중요한 작업에 유리합니다. 각 아키텍처는 설계 목적이 다르기 때문에, 과제에 맞게 선택하는 게 중요합니다.

슬라이드 24: Chain Rule (1분 30초)
이제 수학적 기반을 보겠습니다. 문장의 확률은 연쇄 법칙으로 분해할 수 있습니다. 전체 문장의 확률은 각 단어의 조건부 확률을 곱한 것과 같다는 거죠.

수식으로 보면 P(x1, x2, x3, ..., xn) = P(x1) × P(x2|x1) × P(x3|x1,x2) × ... 이런 식입니다. 첫 번째 단어가 나올 확률, 그 다음 첫 번째가 주어졌을 때 두 번째가 나올 확률, 이런 식으로 곱해나가는 거예요.

이 원리가 바로 LLM의 수학적 토대입니다. 모델은 이 조건부 확률들을 학습하고, 생성할 때는 이 확률들을 차례로 적용하는 거죠.

슬라이드 25: 조건부확률의 직관 (1분 30초)
조건부 확률을 직관적으로 이해해봅시다. 만약 모델이 의학 논문으로만 학습됐다면, "세포는"이라는 말 다음에 "분열한다"가 나올 확률이 높겠죠. 반면 일상 대화로 학습됐다면 다른 단어가 나올 겁니다.

이걸 도메인 분포 이동이라고 합니다. 학습 데이터의 특성이 모델의 확률 분포를 결정하는 거예요. 그래서 범용 모델을 만들려면 다양한 도메인의 데이터를 균형 있게 학습시켜야 합니다.

사전 확률도 중요합니다. 처음 단어를 생성할 때는 문맥이 없으니까요. 이때는 학습 데이터에서 각 단어가 문장 시작 위치에 나타난 빈도가 사전 확률이 됩니다.

슬라이드 26: Perplexity (1분 30초)
모델의 성능을 어떻게 측정할까요? Perplexity라는 지표를 사용합니다. 한국어로는 혼란도 정도로 번역할 수 있는데요.

수식을 보면 교차 엔트로피의 지수 변환입니다. 직관적으로 설명하면, 모델이 다음 단어를 예측할 때 평균적으로 몇 개의 후보 중에서 고민하는지를 나타냅니다. PPL이 10이라면 평균적으로 10개 정도의 후보를 고려한다는 뜻이죠.

낮을수록 좋습니다. PPL이 낮다는 건 모델이 확신을 가지고 예측한다는 의미니까요. 최신 모델들은 PPL이 점점 낮아지는 추세입니다.

슬라이드 27: Temperature 실험 (2분)
Temperature 파라미터의 효과를 실제 예시로 보겠습니다. 같은 프롬프트에 T값만 바꿔서 생성해봤습니다.

T=0.2일 때는 매우 보수적인 문장이 나옵니다. "오늘 날씨가 좋습니다. 산책하기 좋은 날입니다." 처럼 무난하고 예측 가능한 표현들이죠. T=1.0에서는 조금 더 자연스러워집니다. "오늘 날씨 정말 좋네요! 밖에 나가고 싶어지는 날이에요." 이런 식으로요.

T=1.8로 높이면 창의적이지만 때로는 이상한 문장이 나옵니다. "오늘 날씨... 하늘이 춤추는 것 같아요. 구름이 노래하네요." 시적이긴 한데 좀 과하죠. 실무에서는 보통 0.7~1.0 사이를 많이 씁니다.

슬라이드 28: 추론 최적화 (2분)
실제 서비스에서는 속도가 매우 중요합니다. 여러 최적화 기법들이 개발됐는데요.

KV Cache는 앞에서 언급했죠. 이미 계산한 것을 재사용하는 겁니다. Speculative Decoding은 작은 모델로 먼저 예측하고, 큰 모델로 검증하는 방식입니다. 대부분은 작은 모델 예측이 맞으니까 시간을 절약할 수 있죠.

FlashAttention은 어텐션 계산을 메모리 효율적으로 재구성한 겁니다. GPU 메모리 접근 패턴을 최적화해서 속도를 크게 올렸습니다. 이런 기법들을 조합하면 실시간 서비스가 가능해집니다.

슬라이드 29: 안전 가드레일 (1분 30초)
AI의 안전성도 중요한 주제입니다. 모델이 유해한 내용을 생성하지 않도록 가드레일을 설치하는데요.

문제는 안전성과 다양성 사이의 트레이드오프입니다. 너무 강하게 제약하면 정상적인 질문에도 답변을 거부하는 경우가 생깁니다. 이걸 거부 편향이라고 하죠.

예를 들어 "폭탄"이라는 단어만 들어가도 무조건 차단하면, "폭탄 발언의 뜻은 뭔가요?" 같은 정상적인 질문도 막히게 됩니다. 그래서 문맥을 고려한 정교한 필터링이 필요합니다.

슬라이드 30: 도메인별 적용 팁 (2분)
실무에서 도메인별로 어떻게 적용하면 좋을까요? 몇 가지 팁을 드리겠습니다.

제조업에서는 정형화된 포맷이 중요합니다. Temperature를 낮게 설정하고, 템플릿 기반 생성을 권장합니다. 불량 보고서 같은 건 창의성보다 정확성이 중요하니까요.

교육 분야에서는 Persona 설정이 효과적입니다. "당신은 초등학교 선생님입니다"라고 명시하면 설명 수준이 조절됩니다. 공공 분야에서는 RAG를 적극 활용하세요. 외부 문서를 참조하고 근거를 명시하면 신뢰도가 올라갑니다.

각 도메인의 특성을 이해하고 그에 맞는 전략을 수립하는 게 핵심입니다.

슬라이드 31: 한계와 도전과제 (2분)
하지만 현재 기술에도 여전히 한계가 있습니다. 가장 큰 문제는 할루시네이션이죠. 모델이 그럴듯하지만 거짓인 정보를 생성하는 겁니다. 확률 기반이다 보니 "있을 법한" 답을 만들어내는데, 그게 항상 사실은 아니거든요.

Softmax 병목 문제도 있습니다. 모든 가능한 토큰에 대해 확률을 계산해야 하는데, 어휘가 수만 개니까 계산량이 어마어마하죠. 긴 컨텍스트도 문제입니다. 문서 전체를 처리하려면 메모리와 연산량이 제곱으로 증가합니다.

이런 문제들을 해결하기 위한 연구가 활발히 진행 중입니다. 완벽하진 않지만 계속 개선되고 있습니다.

슬라이드 32: 최신 동향 (2분)
마지막으로 최신 기술 동향을 소개하겠습니다. Mixture-of-Experts, MoE는 여러 전문가 모델을 조합하는 방식입니다. 모든 파라미터를 항상 사용하는 게 아니라, 입력에 따라 필요한 전문가만 활성화합니다. 효율성이 크게 올라가죠.

Multi-Token Prediction은 한 번에 여러 토큰을 예측하는 기법입니다. 기존에는 한 번에 하나씩 생성했는데, 여러 개를 동시에 예측하면 속도가 빨라집니다. 도구 사용, Tool Use는 AI가 계산기나 검색 엔진 같은 외부 도구를 활용하게 하는 겁니다. 이렇게 하면 할루시네이션을 줄이고 정확도를 높일 수 있습니다.

슬라이드 33: 실습 과제 (1분 30초)
이론은 여기까지고, 이제 직접 실습해볼 시간입니다. 과제는 파라미터 튜닝 실험인데요.

같은 프롬프트에 Temperature, Top-p, Top-k 값을 바꿔가면서 결과를 비교해보세요. 각 파라미터가 실제로 어떤 영향을 미치는지 체감하는 게 중요합니다. 결과는 이 표에 기록하시면 됩니다.

추천하는 실험 조합은 슬라이드에 나와 있습니다. 시간이 되시면 여러 조합을 시도해보시고, 어떤 설정이 어떤 상황에 적합한지 스스로 판단해보세요. 실습을 통해 이론을 내 것으로 만들 수 있을 겁니다.

슬라이드 34: 요약 및 Q&A (2분)
오늘 배운 내용을 정리하겠습니다. 생성형 AI의 핵심은 확률 분포에서 샘플링하는 것입니다. 무작위처럼 보이지만 학습된 패턴을 따르는 거죠.

우리는 Temperature, Top-k, Top-p 같은 레버로 생성 스타일을 제어할 수 있습니다. 하지만 실무에서는 안전성, 속도, 품질 사이의 균형을 잡아야 합니다. 완벽한 설정은 없고, 상황에 맞게 조율하는 게 중요합니다.

이제 질문 받겠습니다. 오늘 배운 내용 중 궁금한 점이나, 실무에 적용할 때 고민되는 부분이 있으시면 편하게 질문해주세요. 오늘 교육이 여러분의 AI 이해도를 한 단계 높이는 계기가 되었길 바랍니다. 감사합니다.
