📄 보고서 문서 자동 생성 - 발표 스크립트 (50분)
슬라이드 1: 표지 (1분)
안녕하세요, 여러분. 오늘 이 시간에는 Python을 활용한 업무 자동화, 그 중에서도 보고서 문서 자동 생성에 대해 함께 알아보겠습니다.

우리가 일상에서 반복적으로 작성하는 보고서들, 그것들을 자동으로 만들 수 있다면 어떨까요? Raw Data를 입력하면 자동으로 Smart Report가 나오는 시스템을 직접 구축해보는 시간이 될 것입니다.

슬라이드 2: 학습 목표와 진행 방식 (2분)
자, 오늘 우리가 배울 내용을 먼저 정리해볼까요? 크게 네 가지 목표를 가지고 있습니다.

첫째, 데이터 기반의 PDF와 Word 리포트를 자동으로 생성하는 기술을 익히게 됩니다. 둘째는 음성이나 텍스트 인식을 통해서 작업 보고를 간소화하는 방법이죠.

그리고 Pandas, Jinja2, Whisper 같은 핵심 라이브러리들을 실제로 다뤄보면서 Python 코드 중심의 실습을 진행할 겁니다. 마지막으로 입력부터 최종 산출물까지 전체 파이프라인을 이해하게 되실 거예요.

진행 방식은 이론 30%, 실습 70%로 구성됩니다. 손으로 직접 코드를 쳐보면서 배우는 시간이 될 것입니다.

섹션 1 시작: 보고서 자동화 기초 (0.5분)
이제 첫 번째 섹션으로 들어가보겠습니다. 보고서 자동화의 기초 개념과 전체 아키텍처를 살펴볼 텐데요, 실습 환경도 함께 준비해보는 시간이 되겠습니다.

슬라이드 4: 문서 자동화란 무엇인가? (2.5분)
문서 자동화가 정확히 뭘까요? 한마디로 말하면 반복적인 수작업에서 벗어나는 것입니다.

여러분도 경험해보셨을 겁니다. 매일, 매주, 매월 똑같은 형식의 보고서를 작성하면서 데이터만 바꿔 넣는 일. 그걸 이제 데이터로부터 자동으로 생성하게 만드는 거죠.

수동 작업을 최소화한다는 건 단순히 복사 붙여넣기 작업을 없앤다는 의미만이 아닙니다. 서식을 맞추고, 표를 정리하고, 그래프를 삽입하는 모든 과정이 자동화되는 거예요.

기대 효과를 볼까요? 첫째, 데이터베이스나 엑셀 파일에서 실시간으로 데이터를 가져올 수 있습니다. 둘째, 사람이 직접 입력하면서 생기는 실수들을 원천적으로 차단하게 되죠.

가장 놀라운 건 작성 시간입니다. 수 시간 걸리던 리포팅 작업이 말 그대로 수 초 안에 완료됩니다. 90% 시간 단축이라는 게 과장이 아닙니다.

그리고 서식의 일관성도 유지되고, 단순 반복 업무가 사라지면서 업무 피로도가 줄어들게 됩니다. 최신 데이터로 즉각적인 의사결정이 가능해지는 것도 큰 장점이에요.

슬라이드 5: 아키텍처 개요 (3분)
자동화 파이프라인의 전체 구조를 살펴보겠습니다. 크게 세 단계로 나뉩니다.

1단계는 다양한 데이터 입력입니다. CSV나 Excel 같은 정형 데이터부터 시작해서, 데이터베이스에 저장된 정보, 심지어 음성 녹음이나 텍스트 로그 같은 비정형 데이터까지 모두 수집할 수 있죠. 이 모든 걸 Pandas를 통해 표준화된 형태로 변환하게 됩니다.

2단계는 데이터 가공과 템플릿 처리입니다. 수집한 데이터를 분석하고 요약하는 과정이 필요하겠죠? 그리고 나서 미리 정의해둔 템플릿에 데이터를 동적으로 주입합니다. 여기서 Jinja2 같은 템플릿 엔진이 핵심 역할을 하게 되는데요, HTML이나 XML 구조 안에 데이터를 채워 넣는 작업입니다.

3단계는 멀티 포맷 출력입니다. 최종 결과물을 어떤 형태로 만들 것인지 선택할 수 있어요. 인쇄나 공유용으로는 PDF, 재편집이 필요하면 Word, 웹에 게시할 거라면 HTML로 렌더링해서 자동 발송까지 가능합니다.

여기서 가장 중요한 핵심 개념이 하나 있습니다. 데이터 처리 로직과 디자인, 즉 템플릿을 완전히 분리하는 겁니다. 이렇게 하면 나중에 보고서 디자인만 바꾸고 싶을 때 파이썬 코드는 전혀 건드리지 않아도 됩니다. 유지보수성이 획기적으로 높아지는 거죠.

슬라이드 6: 핵심 기술 스택 (2분)
자, 이제 우리가 사용할 도구들을 살펴볼 시간입니다. 크게 세 가지 영역으로 나눠볼 수 있어요.

먼저 데이터 및 문서 처리 영역입니다. Python과 Pandas는 데이터 전처리와 통계 분석의 핵심이죠. Jinja2와 DocxTemplate은 동적으로 내용을 삽입하는 템플릿 엔진이고요, WeasyPrint나 pdfkit은 HTML을 고품질 PDF로 변환해줍니다.

두 번째는 AI 및 자연어 처리 영역입니다. HuggingFace의 Transformers를 활용해서 텍스트 요약이나 분석 모델을 사용하게 되고, OpenAI Whisper로는 음성 인식 작업을 처리할 겁니다. 한국어 텍스트는 KoNLPy나 Kiwi로 형태소 분석을 하게 되죠.

마지막은 시스템 및 배포 영역입니다. FastAPI로 고성능 API 서버를 만들고, Celery로 비동기 작업을 관리하며, Docker로 컨테이너 기반 배포까지 구현할 수 있습니다.

슬라이드 7: 환경 구성 및 설치 (2.5분)
실습 환경을 직접 구성해보겠습니다. 화면의 코드를 따라오시면 됩니다.

첫 번째로 가상환경을 생성하고 활성화합니다. Python 3.10 이상 버전을 권장하는데요, python -m venv .venv 명령어로 가상환경을 만들고, source .venv/bin/activate로 활성화하시면 됩니다. 윈도우 사용자분들은 .venv\Scripts\activate를 실행하시면 되고요.

두 번째는 문서 생성 관련 라이브러리 설치입니다. pandas, jinja2, pdfkit, weasyprint 등 PDF와 Excel, 템플릿 처리에 필요한 패키지들을 한 번에 설치합니다.

세 번째로 텍스트와 음성 처리 라이브러리를 설치하는데요, openai-whisper, transformers, torch 같은 패키지들이 필요합니다. 음성 인식과 자연어 처리를 위한 도구들이죠.

마지막으로 배포와 유틸리티 관련 패키지들을 설치합니다. fastapi, uvicorn, celery, redis 등이 포함되어 있습니다.

여기서 주의하실 점이 있는데요, 외부 의존성이 두 가지 있습니다. 첫째는 FFmpeg인데, Whisper를 구동하려면 반드시 시스템에 설치되어 있어야 합니다. 둘째는 wkhtmltopdf인데, pdfkit을 사용할 때 필요한 바이너리 파일입니다.

슬라이드 8: 프로젝트 폴더 및 데이터 구조 (2.5분)
실습을 위한 디렉토리 구조를 확인해보겠습니다. 체계적인 폴더 구성이 프로젝트 관리의 시작입니다.

먼저 data/raw 폴더입니다. 여기에는 원본 데이터가 들어갑니다. 일일 로그 CSV 파일이나 작업 메모 텍스트, 음성 녹음 파일 등이 저장되는 곳이죠.

templates 폴더에는 Jinja2 기반의 보고서 템플릿 파일들이 위치합니다. HTML 구조와 함께 데이터가 들어갈 위치를 중괄호 두 개로 표시해두는 형태입니다.

src 폴더 안에는 핵심 Python 모듈들이 있습니다. render.py는 HTML 템플릿과 데이터를 결합해서 PDF로 변환하는 렌더링 로직을 담당하고요, summarize.py는 NLP 모델을 활용해서 긴 텍스트를 요약하는 모듈입니다. stt.py는 OpenAI Whisper로 음성을 텍스트로 변환하는 기능을 제공하죠.

마지막으로 outputs 폴더는 최종 결과물이 저장되는 곳입니다. 생성된 PDF 보고서나 차트 이미지, 변환된 텍스트 파일들이 여기에 모입니다.

여기서 중요한 원칙이 하나 있습니다. 모듈화입니다. 데이터 처리 로직과 문서 생성 로직을 분리해두면, 나중에 템플릿 디자인이 바뀌어도 파이썬 코드를 최소한으로만 수정하면 됩니다.

슬라이드 9: 템플릿 엔진 선택 가이드 (2분)
프로젝트 목적에 따라 적합한 문서 생성 도구가 다릅니다. 세 가지를 비교해볼게요.

Jinja2는 HTML 기반입니다. 가장 큰 장점은 높은 디자인 자유도인데요, HTML과 CSS를 활용해서 픽셀 단위의 정교한 스타일링이 가능합니다. WeasyPrint 같은 도구와 결합하면 고품질 인쇄용 문서를 만들 수 있고요, 조건문이나 반복문 같은 강력한 로직 제어 기능도 내장되어 있습니다.

DocxTemplate은 워드 문서를 다룰 때 최적입니다. 이미 회사에서 사용 중인 워드 양식을 그대로 템플릿으로 활용할 수 있다는 게 큰 강점이죠. 개발자가 아니어도 양식 수정이 쉽고, 표나 머리글, 바닥글 같은 워드 고유 기능을 그대로 유지할 수 있습니다.

Markdown은 가장 경량화된 방식입니다. 단순한 문법으로 빠르게 문서를 구조화할 수 있고, 순수 텍스트 포맷이라 Git 같은 버전 관리 시스템과 궁합이 좋습니다. Pandoc을 통해 PDF, HTML, Word 등 다양한 포맷으로 자유롭게 변환할 수 있다는 것도 장점이에요.

슬라이드 10: 보안 및 개인정보 보호 (2분)
자동화 시스템을 구축할 때 반드시 고려해야 할 보안 전략을 살펴보겠습니다.

먼저 개인정보 비식별화입니다. 정규표현식을 활용해서 이름이나 전화번호, 이메일 같은 민감 정보를 자동으로 마스킹 처리해야 합니다. 서버 내부 파일 경로나 IP 주소 같은 정보도 최종 리포트에 노출되지 않도록 필터링하는 게 중요하죠.

두 번째는 데이터 수명 주기 관리입니다. 중간에 생성되는 임시 파일들, HTML이나 JSON, 차트 이미지 같은 것들은 생성 직후나 주기적으로 삭제해야 합니다. 로그와 리포트 파일의 보관 기한도 정책화해서, 예를 들어 3년이 지나면 자동으로 폐기되도록 설정하는 거죠.

세 번째는 감사 추적입니다. 누가 언제 문서를 생성했는지, 어떤 데이터를 사용했는지 메타데이터로 기록해둬야 합니다. 문서 생성 요청과 성공 여부, 접근 이력을 별도 로그 서버에 중앙화해서 관리하고요, PDF 디지털 서명이나 해시 값을 통해 원본 문서의 무결성을 보장할 수도 있습니다.

섹션 2 시작: Python 기반 문서 생성 실습 (0.5분)
이제 본격적인 실습 시간입니다. Markdown부터 시작해서 데이터 집계, 템플릿 엔진까지 단계적으로 자동 리포트를 만들어보겠습니다.

슬라이드 12: 실습 1 - Markdown → PDF (코드 설명) (3분)
가장 간단하게 리포트를 생성하는 방법부터 시작해볼까요? Markdown 문법을 활용하는 방식입니다.

코드를 함께 보시죠. 먼저 필요한 라이브러리를 임포트합니다. markdown은 마크다운 문법을 HTML로 변환해주는 표준 라이브러리고, pdfkit은 HTML을 PDF로 렌더링하는 도구입니다.

1단계에서 변환할 마크다운 텍스트를 정의합니다. 해시 기호 하나면 제목이 되고, 하이픈으로 리스트를 만들 수 있죠. 일일 업무 보고서 형태로 간단하게 작성해봤습니다.

2단계는 마크다운을 HTML 문자열로 변환하는 과정입니다. markdown.markdown() 함수 하나면 끝입니다.

3단계가 중요한데요, wkhtmltopdf 실행 파일 경로를 설정합니다. 특히 윈도우 환경에서는 이 부분이 필수입니다. 경로를 명시적으로 지정하지 않으면 FileNotFoundError가 발생하거든요.

4단계에서 최종적으로 pdfkit.from_string() 함수를 사용해서 HTML을 PDF 파일로 저장합니다.

여기서 한 가지 팁을 드리면, 한글이 깨지는 경우가 있습니다. 그럴 땐 HTML 헤더에 UTF-8 메타 태그를 추가하거나, CSS로 한글 폰트를 명시적으로 지정해주시면 해결됩니다.

변환 프로세스는 Markdown에서 HTML로, 다시 PDF로 가는 2단계 과정입니다. 중간 단계인 HTML에서 CSS 스타일을 적용하면 폰트나 여백 같은 디자인 요소를 자유롭게 제어할 수 있어요.

슬라이드 13: 실습 1 - 실행 파이프라인 (2.5분)
이번엔 마크다운 파일을 읽어서 스타일까지 적용한 완전한 PDF를 생성하는 전체 파이프라인 코드를 보겠습니다.

먼저 변환 옵션을 설정합니다. 용지 크기는 A4로, 인코딩은 UTF-8로 지정하고, 상단과 우측 여백도 0.75인치로 설정합니다.

외부 CSS 파일을 지정하는 부분이 중요한데요, PDF 변환 엔진은 시스템 기본 폰트를 사용하기 때문에 한글이 깨지는 경우가 많습니다. CSS 파일에 나눔고딕 같은 폰트를 명시적으로 지정해주면 이 문제를 해결할 수 있습니다.

Try-Except 구문으로 예외 처리도 해줍니다. MD 파일을 읽을 때 encoding='utf-8'을 꼭 명시해야 한글이 깨지지 않아요. extensions=['tables']를 추가하면 마크다운 테이블 기능도 사용할 수 있습니다.

출력 경로는 outputs/reports/ 같은 구조화된 폴더를 지정해서 관리를 용이하게 만듭니다.

wkhtmltopdf 실행 파일이 없거나 경로가 잘못된 경우 OSError가 발생하는데요, 이럴 때 사용자에게 명확한 에러 메시지를 제공하도록 예외 처리를 구성했습니다.

확장 기능 팁 하나 드리면, 마크다운에 이미지를 넣을 때는 웹 URL보다 절대 경로를 사용하는 게 PDF 렌더링 시 오류를 줄이는 방법입니다.

슬라이드 14: 실습 2 - 데이터 집계 및 차트 이미지화 (3분)
이제 정형화된 보고서를 만들기 위한 핵심 과정입니다. 원본 데이터를 요약하고 차트 이미지로 변환하는 작업을 해보겠습니다.

코드를 보시면, pandas로 데이터를 로드하고 날짜별로 매출을 집계합니다. groupby 함수가 핵심인데요, 날짜별, 카테고리별 합계나 평균을 계산할 수 있습니다. 원본 데이터를 그대로 넣기보다는, 이렇게 인사이트를 줄 수 있는 요약 통계량으로 가공하는 게 중요합니다.

시각화 스타일을 설정하는 부분도 있습니다. seaborn의 whitegrid 테마를 사용하고, 그림 크기를 10x6으로 지정했습니다.

차트 생성은 seaborn의 barplot으로 막대 그래프를 만듭니다. 인터랙티브 웹 차트와 달리 PDF 보고서용 차트는 이미지 파일이어야 하기 때문에, matplotlib이나 seaborn 같은 정적 이미지 생성 도구를 사용하는 겁니다.

plt.savefig() 함수로 이미지를 저장할 때 두 가지 옵션이 중요합니다. dpi=300은 인쇄 가능한 고화질로 저장하는 옵션이고, bbox_inches='tight'는 차트 주변의 불필요한 공백을 제거해서 문서 레이아웃을 깔끔하게 만들어줍니다.

마지막으로 plt.close()를 꼭 호출해야 합니다. 루프를 돌면서 여러 차트를 생성할 때 이전 차트 객체를 메모리에서 해제하지 않으면 서버 리소스가 부족해질 수 있거든요.

슬라이드 15: 실습 2 - 데이터 → 보고서 구현 (3분)
Pandas와 PDFKit을 연동해서 데이터 분석 결과를 시각적인 리포트로 변환하는 핵심 로직입니다.

먼저 데이터프레임을 HTML 테이블로 변환합니다. df.to_html() 메서드 하나면 되는데요, Pandas 데이터프레임을 HTML <table> 태그로 직렬화해줍니다. classes 인자를 통해 CSS 클래스를 적용하면 테이블 스타일을 쉽게 커스터마이징할 수 있어요.

차트 이미지는 절대 경로로 준비해야 합니다. os.path.abspath()를 사용하는 이유는 wkhtmltopdf 엔진이 상대 경로 이미지를 제대로 인식하지 못하는 경우가 많기 때문입니다.

HTML 템플릿에 데이터와 이미지를 삽입하는 부분을 보시죠. f-string을 사용해서 동적으로 값을 채워 넣습니다. 제목, 차트 이미지, 그리고 테이블 HTML을 순서대로 배치합니다.

차트 이미지는 <img> 태그의 src 속성에 로컬 파일 경로를 지정해서 문서에 포함시킵니다. 외부 URL이 아니라 로컬 파일 경로를 사용하는 게 안정적입니다.

최종적으로 조립된 전체 HTML 문자열을 pdfkit.from_string()에 전달하면 PDF 파일이 생성됩니다. 필요하다면 중간 단계에서 .html 파일로 저장해서 웹 브라우저로 레이아웃을 미리 확인할 수도 있습니다.

슬라이드 16: 실습 3 - Jinja2 템플릿 엔진 개요 (3.5분)
이제 Python에서 가장 강력한 템플릿 엔진인 Jinja2를 다뤄보겠습니다. HTML 구조와 데이터를 완벽하게 분리할 수 있는 도구입니다.

먼저 데이터 바인딩 방식을 볼까요? 이중 중괄호 {{ variable }}를 사용합니다. Python 딕셔너리나 객체에서 전달된 값이 HTML 내의 원하는 위치에 출력되는 거죠. 날짜 포맷팅이나 문자열 조작 같은 필터 기능도 지원합니다.

제어 구조는 {% %} 안에 작성합니다. Python과 거의 비슷한 문법이에요. {% for %}로 리스트 데이터를 반복해서 테이블 행이나 리스트 아이템을 동적으로 생성할 수 있고, {% if %}로 데이터 유무나 값에 따라 특정 섹션을 표시하거나 숨길 수 있습니다.

코드 예시를 보시면, {% for item in items %} 반복문 안에서 loop.index로 순서 번호를 출력하고, item.name으로 각 항목의 이름을 표시합니다. 조건부 스타일링도 가능한데요, 값이 음수면 'error' 클래스를, 양수면 'ok' 클래스를 적용하는 식입니다.

요약문이 있을 때만 섹션을 표시하는 조건문도 있습니다. {% if summary_text %}로 체크해서 데이터가 있을 때만 해당 부분을 렌더링하는 거죠.

템플릿 상속 기능도 강력합니다. 웹사이트 개발처럼 base.html에 헤더, 푸터, 공통 스타일을 정의해두고, 개별 리포트 템플릿에서 이걸 상속받아 본문 내용만 채워 넣을 수 있습니다. 유지보수 효율이 극대화되는 거죠.

CSS 인쇄 최적화 팁도 하나 드리면, @page CSS 규칙을 사용하면 A4 용지 여백이나 페이지 번호 위치를 세밀하게 제어할 수 있습니다.

슬라이드 17: 실습 3 - Jinja2 + HTML → PDF (3분)
템플릿 엔진을 활용한 전체 파이프라인을 구축해보겠습니다.

먼저 Jinja2 환경을 설정합니다. FileSystemLoader로 템플릿 폴더 경로를 지정하고, env.get_template()으로 특정 템플릿 파일을 불러옵니다.

동적 데이터, 즉 컨텍스트를 준비하는 부분이 핵심입니다. Python 딕셔너리 형태로 제목, 날짜, 요약문, 통계 데이터 등 리포트에 들어갈 모든 정보를 담습니다. Pandas DataFrame은 to_dict('records')로 변환하면 템플릿 내 반복문에서 쉽게 사용할 수 있어요.

template.render(context)를 호출하면 마법이 일어납니다. Jinja2 엔진이 HTML 템플릿의 변수 {{ var }}와 제어문 {% for %}를 실제 데이터로 치환해서 완성된 HTML 문자열을 반환하는 거죠.

렌더링된 HTML은 두 가지 방식으로 활용할 수 있습니다. 중간 결과물로 저장해서 디버깅용으로 확인하거나, 곧바로 pdfkit에 전달해서 PDF 파일로 변환하는 겁니다.

PDF 변환 시 옵션으로 용지 크기와 인코딩을 지정해줍니다. 이미지 경로 문제를 피하려면 절대 경로를 사용하는 게 안전합니다.

다국어 지역화 팁 하나 드리면, 날짜 포맷이나 숫자 표기는 Python 코드 단에서 미리 포맷팅해서 문자열로 넘겨주는 게 템플릿 복잡도를 줄이는 좋은 방법입니다.

슬라이드 18: 문서 품질 및 성능 개선 팁 (2분)
프로덕션 환경에서 안정적인 자동화 시스템을 구축하려면 최적화 전략이 필요합니다.

렌더링 성능 측면에서는 이미지 캐싱이 중요합니다. 로고나 서명 같이 반복되는 자원은 메모리에 로드해서 I/O를 최소화하세요. 리포트 생성을 Celery 큐로 분리하면 웹 서버 응답성을 확보할 수 있고요, 대량 문서 생성 시에는 Multiprocessing으로 CPU 코어를 최대한 활용하는 게 좋습니다.

출력 품질 향상을 위해서는 폰트를 PDF에 내장해야 모든 기기에서 동일하게 보입니다. 차트는 SVG 포맷으로, 이미지는 300DPI 이상으로 사용하면 인쇄 품질이 깨지지 않아요. 색상 프로파일도 인쇄용 CMYK와 화면용 RGB를 명확히 구분해야 합니다.

재현성과 유지보수 차원에서는 문서 메타데이터에 사용된 데이터와 템플릿 버전을 태깅해두는 게 중요합니다. 템플릿 수정 시 스냅샷 테스트로 기존 문서와 렌더링 결과를 픽셀 단위로 비교하면 예상치 못한 변화를 감지할 수 있고, 렌더링 실패 구간이나 데이터 누락 원인을 파악하기 위한 상세 로그도 필수입니다.

섹션 3 시작: 텍스트 기반 작업보고 자동화 (0.5분)
이제 NLP로 로그나 메모를 정제하고 요약해서 보고 문장을 자동 생성하는 방법을 알아보겠습니다.

슬라이드 20: NLP 기초 파이프라인 (2.5분)
로그나 메모 같은 비정형 텍스트 데이터를 보고서로 변환하는 핵심 과정을 3단계로 정리할 수 있습니다.

1단계는 텍스트 전처리입니다. 데이터 정제 작업으로 특수문자, 이모지, 중복 공백을 제거하고 인코딩을 통일합니다. 토큰화 과정에서는 문장을 단어나 형태소 단위로 분해하는데, Mecab이나 Kiwi 같은 한국어 형태소 분석기를 사용하죠. 불용어 제거도 중요한데, 의미 없는 조사나 어미를 필터링해서 노이즈를 줄입니다.

2단계는 핵심 분석 태스크입니다. 키워드 추출은 TF-IDF 기반으로 주요 이슈와 발생 지점을 파악하는 작업이고요, 텍스트 분류는 로그 레벨이 Info인지 Error인지, 또는 업무 유형을 자동으로 태깅하는 겁니다. 자동 요약은 KoBART 같은 모델로 긴 작업 내역을 핵심 문장으로 압축하는 거죠.

3단계는 활용 도구입니다. 한국어 형태소 분석에는 KoNLPy나 Kiwi를 사용하고, 딥러닝 기반 모델은 Hugging Face Transformers 라이브러리의 BERT나 GPT 계열을 활용합니다. 전통적인 머신러닝 알고리즘이나 TF-IDF는 Scikit-learn으로 처리할 수 있습니다.

슬라이드 21: 실습 4 - 로그 텍스트 정제/파싱 (2.5분)
원시 로그 파일은 그냥 텍스트 덩어리입니다. 이걸 분석 가능한 데이터셋으로 변환하려면 정규표현식이 필요합니다.

코드를 보시면 비정형 로그 데이터 샘플이 있습니다. 타임스탬프, 로그 레벨, 메시지가 섞여 있는 형태죠. 정규표현식 패턴을 정의해서 이 구조를 파싱합니다.

re.findall()이나 re.match()를 사용해서 날짜, 시간, 로그 레벨, 메시지 내용을 각각 추출합니다. 추출한 데이터는 리스트나 딕셔너리에 담아서 Pandas DataFrame으로 변환하면 구조화된 데이터셋이 완성되는 거죠.

이렇게 만든 DataFrame으로 날짜별 오류 발생 건수를 집계하거나, 특정 키워드가 포함된 로그만 필터링하는 식으로 분석을 진행할 수 있습니다.

정규표현식 패턴이 복잡해 보일 수 있는데요, 온라인 정규표현식 테스터를 활용하면 패턴을 실시간으로 검증하면서 작성할 수 있습니다.

슬라이드 22-25: 실습 5 - 자동 요약 (생략, 시간 관계상 요약) (1분)
실습 5에서는 Hugging Face의 KoBART 모델을 활용해서 긴 작업 로그를 요약하는 과정을 다룹니다. 모델을 로드하고, 긴 텍스트를 입력하면 핵심 문장으로 압축된 요약문이 나오는데, 이걸 템플릿에 채워 넣으면 자동 보고서가 완성됩니다. 시간 관계상 상세 코드는 실습 자료를 참고해주시기 바랍니다.

섹션 4 시작: 음성 기반 작업보고 자동화 (0.5분)
이제 음성 인식 기술을 활용해서 작업보고를 더욱 간소화하는 방법을 알아보겠습니다.

슬라이드 26-28: STT 기술 및 Whisper 실습 (2.5분)
OpenAI Whisper는 현존하는 가장 강력한 오픈소스 음성 인식 모델입니다. 한국어도 매우 정확하게 인식하죠.

기본 사용법은 간단합니다. whisper.load_model()로 모델을 불러오고, model.transcribe()에 음성 파일 경로를 넘기면 텍스트로 변환됩니다. 반환값의 ["text"] 키에 인식된 전체 텍스트가 들어있습니다.

실시간 시스템을 구축하려면 마이크 입력을 받아야 합니다. sounddevice 라이브러리로 오디오 스트림을 캡처하고, 일정 시간마다 Whisper 모델에 전달해서 텍스트로 변환합니다. 변환된 텍스트는 앞서 배운 NLP 요약 모델을 거쳐서 최종 보고서 형태로 정리되는 거죠.

전체 파이프라인은 음성 녹음 → STT 변환 → 텍스트 요약 → 템플릿 렌더링 → PDF 생성 순서로 진행됩니다.

섹션 5 시작: 통합 프로젝트 및 마무리 (0.5분)
마지막 섹션에서는 지금까지 배운 모든 걸 통합하는 End-to-End 자동화 시스템을 살펴보겠습니다.

슬라이드 31-32: End-to-End 자동화 아키텍처 (2.5분)
프로덕션 환경에서는 비동기 작업 큐가 필수입니다. Celery와 Redis를 활용한 아키텍처를 보시죠.

사용자가 웹 UI에서 리포트 생성을 요청하면, FastAPI 서버는 즉시 응답을 반환하고 실제 작업은 Celery 워커에 위임합니다. Redis는 작업 큐와 상태를 관리하는 브로커 역할을 하죠.

Celery 워커는 백그라운드에서 데이터 수집, 전처리, 요약, 렌더링, PDF 변환 작업을 순차적으로 처리합니다. 작업이 완료되면 결과 파일 경로를 Redis에 저장하고, 웹 UI는 주기적으로 상태를 폴링해서 완료되면 다운로드 링크를 표시하는 방식입니다.

이런 구조의 장점은 무엇일까요? 첫째, 웹 서버가 블로킹되지 않아서 여러 사용자가 동시에 요청해도 응답성이 유지됩니다. 둘째, 워커를 여러 개 띄워서 수평 확장이 가능합니다. 셋째, 작업 실패 시 자동 재시도 로직을 구현할 수 있습니다.

Docker로 컨테이너화하면 개발 환경과 프로덕션 환경의 일관성을 보장할 수 있고, Kubernetes 같은 오케스트레이션 도구와도 쉽게 통합됩니다.

슬라이드 33-34: 현장 사례 및 교육 마무리 (2분)
실제 현장 사례를 두 가지 소개하겠습니다.

첫 번째는 제조업 일일 생산 리포트 자동화입니다. 매일 밤 자정에 MES 시스템에서 생산 데이터를 추출하고, Pandas로 집계해서 생산량, 불량률, 가동률 차트를 생성합니다. Jinja2 템플릿에 데이터를 주입하고 PDF로 변환한 뒤, 이메일로 자동 발송하는 시스템이죠. 작성 시간이 2시간에서 5분으로 단축됐고, 데이터 입력 오류가 완전히 사라졌습니다.

두 번째는 설비 점검 음성 보고 사례입니다. 현장 작업자가 스마트폰 앱으로 점검 내용을 음성으로 녹음하면, Whisper가 텍스트로 변환하고 KoBART가 핵심 요약문을 생성합니다. 이게 자동으로 점검 보고서 템플릿에 채워져서 PDF가 생성되고, 관리자에게 전송되는 시스템입니다. 현장 작업자는 타이핑할 필요가 없어져서 업무 효율이 크게 올랐습니다.

오늘 배운 내용을 정리하면, 첫째 데이터와 디자인을 분리하는 템플릿 엔진의 중요성, 둘째 정형/비정형 데이터 모두를 활용하는 유연한 파이프라인, 셋째 NLP와 STT로 사람의 개입을 최소화하는 스마트 자동화입니다.

여러분도 오늘 배운 기술을 현장에 적용해서 업무 생산성을 획기적으로 높이시길 바랍니다. 감사합니다.
